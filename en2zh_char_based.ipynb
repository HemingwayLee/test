{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6971b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrowdFlowerAnnotations.txt  Flickr8k.token.txt\t       machine_translation\r\n",
      "ExpertAnnotations.txt\t    Flickr_8k.devImages.txt    readme.txt\r\n",
      "Flicker8k_smaller\t    Flickr_8k.testImages.txt\r\n",
      "Flickr8k.lemma.token.txt    Flickr_8k.trainImages.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d92ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 04:54:26.895879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-18 04:54:31.724660: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-18 04:54:31.724893: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-18 04:54:42.442796: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-18 04:54:42.443770: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-18 04:54:42.443843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2000\n",
      "Number of unique input tokens: 71\n",
      "Number of unique output tokens: 1799\n",
      "Max sequence length for inputs: 163\n",
      "Max sequence length for outputs: 46\n",
      "\n",
      "input data set:\n",
      "['Dad bought me a camera.', \"There's no way to win.\", 'They rescued the boy from drowning.', \"Tom isn't doing what he's supposed to be doing.\", 'When he retired, his son took over the business.', 'Tom swims very fast.', 'Do you know the concert schedule of London Symphony Orchestra?', 'I do not know whether to accept or to refuse.', 'Come if you can.', 'Can you just please go?']\n",
      "\n",
      "target data set:\n",
      "['\\t爸爸给我买了一个照相机。\\n', '\\t沒有辦法贏。\\n', '\\t他們救了這個男孩，使他免於淹死。\\n', '\\t湯姆沒有做他該做的事。\\n', '\\t他退休的时候，他儿子接手了他的生意。\\n', '\\t湯姆游泳游得非常快。\\n', '\\t你知道伦敦交响乐团的演奏会行程吗？\\n', '\\t我不知道是否該同意或拒絕。\\n', '\\t如果你能就來吧。\\n', '\\t能請你離開嗎？\\n']\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "batch_size = 16  # Batch size for training.\n",
    "epochs = 35  # Number of epochs to train for.\n",
    "latent_dim = 128  # Latent dimensionality of the encoding space.\n",
    "num_samples = 2000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = '../../data/machine_translation/cmn.txt'\n",
    "\n",
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "# for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "for line in random.sample(lines, num_samples):\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    \n",
    "    # We use \"\\t\" as the \"start sequence\" char and \"\\n\" as \"end sequence\" char\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    \n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    \n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "print(\"\\ninput data set:\")\n",
    "print(input_texts[:10])\n",
    "print(\"\\ntarget data set:\")\n",
    "print(target_texts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c06e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input index:\n",
      "{' ': 0, '!': 1, '\"': 2, '$': 3, '%': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '0': 9, '1': 10, '2': 11, '3': 12, '4': 13, '5': 14, '6': 15, '7': 16, '8': 17, '9': 18, ':': 19, '?': 20, 'A': 21, 'B': 22, 'C': 23, 'D': 24, 'E': 25, 'F': 26, 'G': 27, 'H': 28, 'I': 29, 'J': 30, 'K': 31, 'L': 32, 'M': 33, 'N': 34, 'O': 35, 'P': 36, 'Q': 37, 'R': 38, 'S': 39, 'T': 40, 'U': 41, 'V': 42, 'W': 43, 'Y': 44, 'a': 45, 'b': 46, 'c': 47, 'd': 48, 'e': 49, 'f': 50, 'g': 51, 'h': 52, 'i': 53, 'j': 54, 'k': 55, 'l': 56, 'm': 57, 'n': 58, 'o': 59, 'p': 60, 'q': 61, 'r': 62, 's': 63, 't': 64, 'u': 65, 'v': 66, 'w': 67, 'x': 68, 'y': 69, 'z': 70}\n",
      "\n",
      "target index:\n",
      "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, ',': 5, '0': 6, '1': 7, '2': 8, '3': 9, '4': 10, '5': 11, '6': 12, '7': 13, '8': 14, '9': 15, '?': 16, 'A': 17, 'C': 18, 'D': 19, 'F': 20, 'I': 21, 'M': 22, 'T': 23, 'a': 24, 'b': 25, 'c': 26, 'e': 27, 'i': 28, 'k': 29, 'm': 30, 'o': 31, 'r': 32, 't': 33, 'w': 34, 'y': 35, '·': 36, '‘': 37, '“': 38, '”': 39, '。': 40, '「': 41, '」': 42, '一': 43, '七': 44, '丈': 45, '三': 46, '上': 47, '下': 48, '不': 49, '与': 50, '专': 51, '且': 52, '世': 53, '业': 54, '东': 55, '丝': 56, '丟': 57, '丢': 58, '两': 59, '严': 60, '並': 61, '个': 62, '中': 63, '为': 64, '主': 65, '丽': 66, '举': 67, '久': 68, '么': 69, '义': 70, '之': 71, '乎': 72, '乏': 73, '乐': 74, '乘': 75, '九': 76, '也': 77, '习': 78, '书': 79, '买': 80, '了': 81, '争': 82, '事': 83, '二': 84, '于': 85, '互': 86, '五': 87, '亚': 88, '些': 89, '亞': 90, '交': 91, '产': 92, '享': 93, '京': 94, '亮': 95, '亲': 96, '人': 97, '什': 98, '仅': 99, '今': 100, '介': 101, '仍': 102, '从': 103, '仔': 104, '他': 105, '付': 106, '代': 107, '令': 108, '以': 109, '仪': 110, '们': 111, '件': 112, '价': 113, '任': 114, '份': 115, '伊': 116, '伏': 117, '休': 118, '优': 119, '伙': 120, '会': 121, '伞': 122, '伟': 123, '传': 124, '伤': 125, '伦': 126, '伯': 127, '伸': 128, '似': 129, '但': 130, '位': 131, '低': 132, '住': 133, '体': 134, '何': 135, '余': 136, '作': 137, '你': 138, '佩': 139, '使': 140, '來': 141, '例': 142, '供': 143, '侵': 144, '便': 145, '促': 146, '俄': 147, '保': 148, '信': 149, '修': 150, '俱': 151, '個': 152, '倍': 153, '們': 154, '倒': 155, '候': 156, '借': 157, '倦': 158, '倫': 159, '债': 160, '值': 161, '假': 162, '偉': 163, '做': 164, '停': 165, '健': 166, '偶': 167, '偷': 168, '傍': 169, '傘': 170, '備': 171, '傳': 172, '傷': 173, '傻': 174, '像': 175, '僱': 176, '價': 177, '儘': 178, '優': 179, '儿': 180, '允': 181, '元': 182, '兄': 183, '充': 184, '先': 185, '光': 186, '克': 187, '免': 188, '兒': 189, '兜': 190, '入': 191, '內': 192, '全': 193, '兩': 194, '八': 195, '公': 196, '六': 197, '兰': 198, '共': 199, '关': 200, '兴': 201, '其': 202, '典': 203, '内': 204, '册': 205, '再': 206, '冒': 207, '写': 208, '农': 209, '冥': 210, '冬': 211, '冰': 212, '冲': 213, '决': 214, '冷': 215, '冻': 216, '净': 217, '准': 218, '凉': 219, '减': 220, '凝': 221, '几': 222, '凡': 223, '出': 224, '击': 225, '刀': 226, '分': 227, '切': 228, '划': 229, '列': 230, '刚': 231, '删': 232, '別': 233, '利': 234, '刪': 235, '别': 236, '刮': 237, '到': 238, '制': 239, '刷': 240, '刻': 241, '則': 242, '前': 243, '剛': 244, '剧': 245, '剩': 246, '劃': 247, '劇': 248, '力': 249, '办': 250, '功': 251, '加': 252, '务': 253, '动': 254, '助': 255, '努': 256, '劫': 257, '劲': 258, '劳': 259, '勇': 260, '動': 261, '務': 262, '勝': 263, '勵': 264, '勸': 265, '包': 266, '化': 267, '北': 268, '匙': 269, '匪': 270, '匱': 271, '区': 272, '医': 273, '區': 274, '十': 275, '升': 276, '午': 277, '半': 278, '单': 279, '卖': 280, '博': 281, '卡': 282, '印': 283, '危': 284, '即': 285, '卷': 286, '卻': 287, '厅': 288, '历': 289, '厌': 290, '厘': 291, '厚': 292, '原': 293, '厨': 294, '厭': 295, '去': 296, '参': 297, '參': 298, '又': 299, '及': 300, '友': 301, '双': 302, '反': 303, '发': 304, '叔': 305, '取': 306, '受': 307, '变': 308, '叢': 309, '口': 310, '古': 311, '句': 312, '另': 313, '只': 314, '叫': 315, '可': 316, '台': 317, '史': 318, '右': 319, '号': 320, '司': 321, '吃': 322, '各': 323, '合': 324, '吉': 325, '同': 326, '名': 327, '后': 328, '向': 329, '吗': 330, '否': 331, '吧': 332, '含': 333, '听': 334, '吵': 335, '吸': 336, '呆': 337, '告': 338, '员': 339, '呢': 340, '周': 341, '味': 342, '呼': 343, '命': 344, '咆': 345, '和': 346, '咎': 347, '咖': 348, '咪': 349, '咱': 350, '品': 351, '响': 352, '員': 353, '哥': 354, '哦': 355, '哨': 356, '哪': 357, '哭': 358, '哮': 359, '哲': 360, '售': 361, '唯': 362, '唱': 363, '唸': 364, '商': 365, '啊': 366, '問': 367, '啡': 368, '啤': 369, '啥': 370, '善': 371, '喘': 372, '喜': 373, '喝': 374, '單': 375, '嗎': 376, '嘛': 377, '嘲': 378, '嘴': 379, '器': 380, '噪': 381, '嚇': 382, '嚴': 383, '囚': 384, '四': 385, '回': 386, '因': 387, '团': 388, '园': 389, '困': 390, '围': 391, '固': 392, '国': 393, '图': 394, '圆': 395, '圈': 396, '國': 397, '園': 398, '圓': 399, '圖': 400, '土': 401, '在': 402, '地': 403, '场': 404, '址': 405, '坏': 406, '坐': 407, '块': 408, '坚': 409, '垒': 410, '埃': 411, '埋': 412, '城': 413, '域': 414, '基': 415, '堂': 416, '堅': 417, '堡': 418, '報': 419, '場': 420, '塔': 421, '填': 422, '境': 423, '墙': 424, '壓': 425, '壞': 426, '士': 427, '声': 428, '处': 429, '备': 430, '复': 431, '夏': 432, '外': 433, '多': 434, '夜': 435, '够': 436, '夠': 437, '夢': 438, '大': 439, '天': 440, '太': 441, '夫': 442, '央': 443, '失': 444, '头': 445, '奇': 446, '奏': 447, '契': 448, '套': 449, '女': 450, '奶': 451, '她': 452, '好': 453, '如': 454, '妈': 455, '妒': 456, '妙': 457, '妹': 458, '妻': 459, '姆': 460, '姊': 461, '始': 462, '姐': 463, '姓': 464, '娃': 465, '娶': 466, '婚': 467, '媽': 468, '嫁': 469, '嫉': 470, '嫌': 471, '子': 472, '字': 473, '存': 474, '季': 475, '孤': 476, '学': 477, '孩': 478, '學': 479, '宁': 480, '它': 481, '守': 482, '安': 483, '完': 484, '官': 485, '定': 486, '宝': 487, '实': 488, '客': 489, '室': 490, '害': 491, '家': 492, '容': 493, '寄': 494, '密': 495, '富': 496, '寓': 497, '察': 498, '實': 499, '寧': 500, '寫': 501, '对': 502, '寺': 503, '导': 504, '封': 505, '将': 506, '將': 507, '專': 508, '對': 509, '導': 510, '小': 511, '少': 512, '尝': 513, '就': 514, '尽': 515, '局': 516, '居': 517, '屆': 518, '屈': 519, '屋': 520, '屏': 521, '属': 522, '履': 523, '山': 524, '岁': 525, '岛': 526, '崗': 527, '巔': 528, '州': 529, '工': 530, '左': 531, '巧': 532, '差': 533, '己': 534, '已': 535, '巴': 536, '巾': 537, '市': 538, '布': 539, '师': 540, '希': 541, '带': 542, '師': 543, '席': 544, '帮': 545, '帳': 546, '帶': 547, '常': 548, '帽': 549, '幅': 550, '幕': 551, '幚': 552, '幫': 553, '干': 554, '平': 555, '年': 556, '并': 557, '幸': 558, '幺': 559, '幼': 560, '幾': 561, '广': 562, '庆': 563, '床': 564, '序': 565, '库': 566, '应': 567, '底': 568, '店': 569, '庙': 570, '废': 571, '度': 572, '座': 573, '庭': 574, '康': 575, '廉': 576, '廚': 577, '廣': 578, '延': 579, '建': 580, '开': 581, '弃': 582, '弄': 583, '式': 584, '引': 585, '弟': 586, '张': 587, '張': 588, '弹': 589, '彈': 590, '彎': 591, '当': 592, '形': 593, '彩': 594, '影': 595, '彼': 596, '往': 597, '待': 598, '很': 599, '律': 600, '後': 601, '得': 602, '從': 603, '復': 604, '微': 605, '德': 606, '心': 607, '必': 608, '忍': 609, '志': 610, '忘': 611, '忙': 612, '忠': 613, '忧': 614, '快': 615, '念': 616, '怀': 617, '怎': 618, '怒': 619, '怕': 620, '怜': 621, '思': 622, '急': 623, '性': 624, '怨': 625, '怪': 626, '总': 627, '恐': 628, '恢': 629, '恨': 630, '息': 631, '恰': 632, '恶': 633, '悔': 634, '您': 635, '情': 636, '惊': 637, '惜': 638, '惯': 639, '想': 640, '惹': 641, '愉': 642, '意': 643, '愚': 644, '愛': 645, '感': 646, '愿': 647, '慎': 648, '慕': 649, '慢': 650, '慮': 651, '憤': 652, '憾': 653, '懂': 654, '應': 655, '懊': 656, '懲': 657, '戏': 658, '成': 659, '我': 660, '戒': 661, '或': 662, '战': 663, '戚': 664, '戰': 665, '戲': 666, '戴': 667, '戶': 668, '户': 669, '房': 670, '所': 671, '手': 672, '才': 673, '扑': 674, '扒': 675, '打': 676, '扔': 677, '托': 678, '执': 679, '扰': 680, '找': 681, '承': 682, '技': 683, '把': 684, '抓': 685, '投': 686, '抢': 687, '护': 688, '报': 689, '披': 690, '抱': 691, '抵': 692, '抹': 693, '抽': 694, '担': 695, '拉': 696, '拍': 697, '拐': 698, '拒': 699, '招': 700, '拜': 701, '拥': 702, '择': 703, '拼': 704, '拾': 705, '拿': 706, '持': 707, '指': 708, '按': 709, '挡': 710, '挥': 711, '捐': 712, '捕': 713, '换': 714, '据': 715, '捷': 716, '掃': 717, '掉': 718, '掌': 719, '排': 720, '掛': 721, '探': 722, '接': 723, '控': 724, '推': 725, '提': 726, '插': 727, '換': 728, '握': 729, '搖': 730, '搜': 731, '搞': 732, '搬': 733, '搭': 734, '搶': 735, '携': 736, '摧': 737, '摩': 738, '摸': 739, '撞': 740, '播': 741, '擁': 742, '擅': 743, '擇': 744, '擔': 745, '據': 746, '擦': 747, '擺': 748, '擾': 749, '攜': 750, '支': 751, '收': 752, '改': 753, '放': 754, '政': 755, '故': 756, '效': 757, '敌': 758, '敏': 759, '救': 760, '敗': 761, '教': 762, '敢': 763, '散': 764, '敦': 765, '数': 766, '整': 767, '數': 768, '文': 769, '料': 770, '斯': 771, '新': 772, '斷': 773, '方': 774, '於': 775, '旁': 776, '旅': 777, '旗': 778, '无': 779, '日': 780, '旧': 781, '早': 782, '时': 783, '旺': 784, '昂': 785, '明': 786, '易': 787, '星': 788, '映': 789, '春': 790, '昨': 791, '是': 792, '显': 793, '時': 794, '晕': 795, '晚': 796, '晤': 797, '晨': 798, '智': 799, '暑': 800, '暖': 801, '暗': 802, '曆': 803, '曲': 804, '更': 805, '書': 806, '曾': 807, '最': 808, '會': 809, '月': 810, '有': 811, '朋': 812, '服': 813, '望': 814, '期': 815, '木': 816, '未': 817, '末': 818, '本': 819, '术': 820, '朵': 821, '机': 822, '杀': 823, '杂': 824, '李': 825, '村': 826, '束': 827, '条': 828, '来': 829, '杯': 830, '杰': 831, '東': 832, '松': 833, '板': 834, '极': 835, '林': 836, '果': 837, '枪': 838, '架': 839, '某': 840, '染': 841, '柜': 842, '查': 843, '柳': 844, '柴': 845, '栋': 846, '校': 847, '样': 848, '根': 849, '格': 850, '案': 851, '桌': 852, '條': 853, '梦': 854, '检': 855, '棄': 856, '棋': 857, '棒': 858, '棕': 859, '棟': 860, '森': 861, '椅': 862, '植': 863, '楚': 864, '業': 865, '極': 866, '楼': 867, '榨': 868, '榮': 869, '槍': 870, '樂': 871, '樓': 872, '標': 873, '樣': 874, '樹': 875, '橋': 876, '橘': 877, '橙': 878, '機': 879, '橫': 880, '檢': 881, '欠': 882, '次': 883, '欢': 884, '欲': 885, '欺': 886, '歇': 887, '歉': 888, '歌': 889, '歐': 890, '歡': 891, '止': 892, '正': 893, '此': 894, '步': 895, '武': 896, '歲': 897, '歸': 898, '死': 899, '殊': 900, '段': 901, '殺': 902, '毁': 903, '母': 904, '每': 905, '比': 906, '毫': 907, '民': 908, '气': 909, '氛': 910, '氣': 911, '水': 912, '永': 913, '汁': 914, '求': 915, '汤': 916, '決': 917, '汽': 918, '沉': 919, '沏': 920, '沒': 921, '沙': 922, '没': 923, '河': 924, '油': 925, '治': 926, '泉': 927, '泊': 928, '法': 929, '波': 930, '泣': 931, '注': 932, '泪': 933, '泰': 934, '泳': 935, '洋': 936, '洗': 937, '洲': 938, '活': 939, '洽': 940, '派': 941, '流': 942, '测': 943, '浪': 944, '浮': 945, '海': 946, '消': 947, '淆': 948, '淇': 949, '淋': 950, '淡': 951, '深': 952, '混': 953, '淹': 954, '清': 955, '渡': 956, '温': 957, '測': 958, '游': 959, '湖': 960, '湯': 961, '湿': 962, '源': 963, '準': 964, '溜': 965, '溝': 966, '溫': 967, '滑': 968, '满': 969, '滾': 970, '滿': 971, '漂': 972, '漆': 973, '漏': 974, '演': 975, '漢': 976, '漫': 977, '漲': 978, '漸': 979, '潤': 980, '潮': 981, '澡': 982, '澳': 983, '激': 984, '濃': 985, '濟': 986, '灑': 987, '火': 988, '灯': 989, '灵': 990, '灾': 991, '炎': 992, '炭': 993, '点': 994, '為': 995, '烛': 996, '烦': 997, '烧': 998, '热': 999, '無': 1000, '然': 1001, '煙': 1002, '煤': 1003, '照': 1004, '煩': 1005, '熟': 1006, '熱': 1007, '燃': 1008, '燈': 1009, '燒': 1010, '燙': 1011, '營': 1012, '爆': 1013, '爬': 1014, '爭': 1015, '爱': 1016, '父': 1017, '爸': 1018, '爺': 1019, '爾': 1020, '牆': 1021, '片': 1022, '版': 1023, '牌': 1024, '牙': 1025, '牛': 1026, '牢': 1027, '物': 1028, '牲': 1029, '特': 1030, '犯': 1031, '犹': 1032, '狐': 1033, '狗': 1034, '独': 1035, '狱': 1036, '狸': 1037, '猜': 1038, '猫': 1039, '献': 1040, '猴': 1041, '獄': 1042, '獨': 1043, '獻': 1044, '王': 1045, '玛': 1046, '玩': 1047, '玫': 1048, '环': 1049, '现': 1050, '玻': 1051, '班': 1052, '現': 1053, '球': 1054, '理': 1055, '琴': 1056, '瑞': 1057, '瑪': 1058, '瑰': 1059, '璃': 1060, '環': 1061, '瓜': 1062, '瓶': 1063, '甚': 1064, '甜': 1065, '生': 1066, '產': 1067, '用': 1068, '田': 1069, '由': 1070, '电': 1071, '男': 1072, '画': 1073, '界': 1074, '留': 1075, '畜': 1076, '畢': 1077, '略': 1078, '畫': 1079, '異': 1080, '當': 1081, '疑': 1082, '疯': 1083, '病': 1084, '痛': 1085, '瘋': 1086, '瘦': 1087, '癌': 1088, '發': 1089, '白': 1090, '百': 1091, '的': 1092, '盈': 1093, '盐': 1094, '监': 1095, '盒': 1096, '盗': 1097, '盡': 1098, '監': 1099, '目': 1100, '盯': 1101, '盲': 1102, '直': 1103, '相': 1104, '盼': 1105, '省': 1106, '看': 1107, '真': 1108, '眶': 1109, '眼': 1110, '着': 1111, '睛': 1112, '睡': 1113, '瞎': 1114, '知': 1115, '矩': 1116, '短': 1117, '石': 1118, '砍': 1119, '研': 1120, '破': 1121, '确': 1122, '碎': 1123, '碗': 1124, '碟': 1125, '碰': 1126, '確': 1127, '碼': 1128, '磅': 1129, '示': 1130, '礼': 1131, '社': 1132, '祇': 1133, '祈': 1134, '祖': 1135, '祝': 1136, '神': 1137, '祟': 1138, '票': 1139, '祸': 1140, '禍': 1141, '福': 1142, '禮': 1143, '离': 1144, '秀': 1145, '私': 1146, '种': 1147, '科': 1148, '秘': 1149, '租': 1150, '积': 1151, '称': 1152, '移': 1153, '程': 1154, '稍': 1155, '稚': 1156, '種': 1157, '稻': 1158, '稽': 1159, '積': 1160, '究': 1161, '穷': 1162, '空': 1163, '穿': 1164, '突': 1165, '窗': 1166, '窮': 1167, '立': 1168, '站': 1169, '竞': 1170, '章': 1171, '端': 1172, '笑': 1173, '笔': 1174, '符': 1175, '第': 1176, '筆': 1177, '等': 1178, '答': 1179, '简': 1180, '箏': 1181, '算': 1182, '管': 1183, '箱': 1184, '節': 1185, '篷': 1186, '簡': 1187, '簽': 1188, '簾': 1189, '籌': 1190, '籍': 1191, '米': 1192, '类': 1193, '粉': 1194, '精': 1195, '糊': 1196, '糕': 1197, '糖': 1198, '糟': 1199, '系': 1200, '紀': 1201, '約': 1202, '紅': 1203, '紉': 1204, '納': 1205, '紐': 1206, '紙': 1207, '索': 1208, '紧': 1209, '累': 1210, '細': 1211, '紹': 1212, '終': 1213, '結': 1214, '絕': 1215, '給': 1216, '綁': 1217, '經': 1218, '綠': 1219, '維': 1220, '網': 1221, '緊': 1222, '線': 1223, '練': 1224, '縫': 1225, '總': 1226, '績': 1227, '繪': 1228, '繫': 1229, '繼': 1230, '續': 1231, '纠': 1232, '红': 1233, '约': 1234, '纪': 1235, '纫': 1236, '纯': 1237, '纸': 1238, '纽': 1239, '练': 1240, '终': 1241, '经': 1242, '结': 1243, '给': 1244, '绝': 1245, '统': 1246, '继': 1247, '绪': 1248, '续': 1249, '缝': 1250, '缺': 1251, '网': 1252, '罕': 1253, '罗': 1254, '罢': 1255, '罪': 1256, '罰': 1257, '羅': 1258, '美': 1259, '群': 1260, '義': 1261, '翁': 1262, '習': 1263, '翔': 1264, '翻': 1265, '老': 1266, '考': 1267, '者': 1268, '而': 1269, '耍': 1270, '耐': 1271, '耳': 1272, '耶': 1273, '聊': 1274, '职': 1275, '聖': 1276, '聚': 1277, '聞': 1278, '聪': 1279, '聯': 1280, '聰': 1281, '聲': 1282, '職': 1283, '聽': 1284, '肉': 1285, '肥': 1286, '肯': 1287, '育': 1288, '肺': 1289, '胃': 1290, '胆': 1291, '背': 1292, '胎': 1293, '胖': 1294, '胜': 1295, '胞': 1296, '胡': 1297, '胳': 1298, '能': 1299, '脑': 1300, '脫': 1301, '脱': 1302, '脸': 1303, '脹': 1304, '腆': 1305, '腕': 1306, '腰': 1307, '腿': 1308, '膊': 1309, '膝': 1310, '膠': 1311, '臂': 1312, '臉': 1313, '自': 1314, '至': 1315, '與': 1316, '興': 1317, '舉': 1318, '舒': 1319, '舞': 1320, '般': 1321, '船': 1322, '良': 1323, '艰': 1324, '色': 1325, '艺': 1326, '节': 1327, '花': 1328, '苍': 1329, '苦': 1330, '英': 1331, '苹': 1332, '茶': 1333, '草': 1334, '荐': 1335, '荧': 1336, '莊': 1337, '莎': 1338, '莓': 1339, '获': 1340, '菜': 1341, '萄': 1342, '营': 1343, '落': 1344, '著': 1345, '葡': 1346, '董': 1347, '蒼': 1348, '蓋': 1349, '蓝': 1350, '蔭': 1351, '薩': 1352, '藍': 1353, '藝': 1354, '藥': 1355, '蘋': 1356, '虎': 1357, '虑': 1358, '處': 1359, '號': 1360, '蚊': 1361, '蛇': 1362, '蛋': 1363, '蛙': 1364, '蛛': 1365, '蜘': 1366, '蜡': 1367, '螂': 1368, '融': 1369, '蟑': 1370, '蠅': 1371, '蠢': 1372, '血': 1373, '行': 1374, '術': 1375, '街': 1376, '衣': 1377, '表': 1378, '袋': 1379, '袜': 1380, '被': 1381, '裂': 1382, '装': 1383, '裝': 1384, '裡': 1385, '裹': 1386, '製': 1387, '褐': 1388, '褲': 1389, '西': 1390, '要': 1391, '覆': 1392, '見': 1393, '規': 1394, '視': 1395, '親': 1396, '覺': 1397, '觀': 1398, '见': 1399, '观': 1400, '规': 1401, '视': 1402, '览': 1403, '觉': 1404, '角': 1405, '解': 1406, '言': 1407, '訂': 1408, '計': 1409, '討': 1410, '記': 1411, '訪': 1412, '許': 1413, '訴': 1414, '評': 1415, '詞': 1416, '試': 1417, '詩': 1418, '話': 1419, '該': 1420, '詳': 1421, '誌': 1422, '認': 1423, '誕': 1424, '語': 1425, '誤': 1426, '說': 1427, '誰': 1428, '課': 1429, '調': 1430, '談': 1431, '請': 1432, '論': 1433, '諾': 1434, '謀': 1435, '講': 1436, '謝': 1437, '證': 1438, '識': 1439, '警': 1440, '譯': 1441, '議': 1442, '護': 1443, '譽': 1444, '讀': 1445, '變': 1446, '讓': 1447, '计': 1448, '认': 1449, '讨': 1450, '让': 1451, '训': 1452, '议': 1453, '记': 1454, '讲': 1455, '讶': 1456, '许': 1457, '论': 1458, '设': 1459, '访': 1460, '证': 1461, '评': 1462, '识': 1463, '诉': 1464, '词': 1465, '试': 1466, '诚': 1467, '话': 1468, '该': 1469, '语': 1470, '误': 1471, '说': 1472, '请': 1473, '诺': 1474, '读': 1475, '课': 1476, '谁': 1477, '谅': 1478, '谈': 1479, '谎': 1480, '谐': 1481, '谢': 1482, '谨': 1483, '豐': 1484, '象': 1485, '豫': 1486, '貌': 1487, '貝': 1488, '負': 1489, '財': 1490, '責': 1491, '貴': 1492, '買': 1493, '費': 1494, '資': 1495, '賣': 1496, '質': 1497, '賬': 1498, '購': 1499, '賽': 1500, '贏': 1501, '负': 1502, '责': 1503, '败': 1504, '货': 1505, '质': 1506, '贵': 1507, '费': 1508, '赏': 1509, '赛': 1510, '赢': 1511, '走': 1512, '赶': 1513, '起': 1514, '超': 1515, '越': 1516, '趕': 1517, '趣': 1518, '足': 1519, '跑': 1520, '跟': 1521, '跡': 1522, '跨': 1523, '路': 1524, '跳': 1525, '踩': 1526, '身': 1527, '車': 1528, '軍': 1529, '軟': 1530, '較': 1531, '輕': 1532, '輛': 1533, '輪': 1534, '轉': 1535, '车': 1536, '轨': 1537, '转': 1538, '轮': 1539, '轻': 1540, '较': 1541, '辆': 1542, '辈': 1543, '辛': 1544, '辜': 1545, '辞': 1546, '辣': 1547, '辦': 1548, '辨': 1549, '辭': 1550, '边': 1551, '迅': 1552, '过': 1553, '迎': 1554, '运': 1555, '近': 1556, '还': 1557, '这': 1558, '进': 1559, '远': 1560, '违': 1561, '迟': 1562, '迪': 1563, '迫': 1564, '迷': 1565, '追': 1566, '退': 1567, '送': 1568, '适': 1569, '逃': 1570, '逆': 1571, '选': 1572, '透': 1573, '递': 1574, '途': 1575, '這': 1576, '通': 1577, '逛': 1578, '速': 1579, '造': 1580, '連': 1581, '逮': 1582, '週': 1583, '進': 1584, '逼': 1585, '遇': 1586, '遊': 1587, '運': 1588, '遍': 1589, '過': 1590, '道': 1591, '達': 1592, '違': 1593, '遗': 1594, '遛': 1595, '遞': 1596, '遠': 1597, '適': 1598, '遭': 1599, '遲': 1600, '選': 1601, '遺': 1602, '邀': 1603, '還': 1604, '邊': 1605, '那': 1606, '邻': 1607, '郎': 1608, '部': 1609, '郵': 1610, '都': 1611, '酒': 1612, '酪': 1613, '酬': 1614, '酸': 1615, '醉': 1616, '醫': 1617, '释': 1618, '釋': 1619, '里': 1620, '重': 1621, '量': 1622, '金': 1623, '鉤': 1624, '鉴': 1625, '銀': 1626, '鋪': 1627, '鋼': 1628, '錄': 1629, '錢': 1630, '錯': 1631, '錶': 1632, '鍊': 1633, '鎖': 1634, '鎮': 1635, '鐘': 1636, '鑰': 1637, '针': 1638, '钟': 1639, '钢': 1640, '钥': 1641, '钱': 1642, '铅': 1643, '银': 1644, '销': 1645, '锁': 1646, '锈': 1647, '错': 1648, '锤': 1649, '镜': 1650, '長': 1651, '长': 1652, '門': 1653, '開': 1654, '間': 1655, '閱': 1656, '關': 1657, '门': 1658, '闪': 1659, '闭': 1660, '问': 1661, '闲': 1662, '间': 1663, '闻': 1664, '阅': 1665, '队': 1666, '阱': 1667, '阳': 1668, '阻': 1669, '附': 1670, '际': 1671, '陋': 1672, '陌': 1673, '降': 1674, '院': 1675, '除': 1676, '险': 1677, '陷': 1678, '随': 1679, '隔': 1680, '際': 1681, '障': 1682, '隨': 1683, '險': 1684, '隻': 1685, '难': 1686, '雅': 1687, '雙': 1688, '雜': 1689, '雞': 1690, '離': 1691, '難': 1692, '雨': 1693, '雪': 1694, '雲': 1695, '電': 1696, '需': 1697, '震': 1698, '露': 1699, '青': 1700, '静': 1701, '靜': 1702, '非': 1703, '靠': 1704, '面': 1705, '靦': 1706, '革': 1707, '鞋': 1708, '音': 1709, '頁': 1710, '順': 1711, '須': 1712, '預': 1713, '頓': 1714, '頬': 1715, '頭': 1716, '顆': 1717, '題': 1718, '顏': 1719, '願': 1720, '顧': 1721, '顯': 1722, '页': 1723, '顶': 1724, '项': 1725, '须': 1726, '顾': 1727, '顿': 1728, '预': 1729, '领': 1730, '题': 1731, '颜': 1732, '風': 1733, '风': 1734, '飛': 1735, '飞': 1736, '食': 1737, '飯': 1738, '飲': 1739, '餐': 1740, '餓': 1741, '餘': 1742, '館': 1743, '饑': 1744, '饭': 1745, '饱': 1746, '饿': 1747, '馆': 1748, '首': 1749, '香': 1750, '馬': 1751, '駕': 1752, '駛': 1753, '驗': 1754, '驚': 1755, '马': 1756, '驶': 1757, '骂': 1758, '验': 1759, '骑': 1760, '骗': 1761, '髒': 1762, '體': 1763, '高': 1764, '髮': 1765, '鬆': 1766, '鬍': 1767, '鬥': 1768, '鬼': 1769, '魁': 1770, '魂': 1771, '魔': 1772, '魚': 1773, '鱼': 1774, '鲑': 1775, '鳥': 1776, '鶴': 1777, '鸟': 1778, '鸡': 1779, '鹽': 1780, '麗': 1781, '麦': 1782, '麵': 1783, '麻': 1784, '麼': 1785, '黎': 1786, '黑': 1787, '默': 1788, '點': 1789, '齦': 1790, '齿': 1791, '龄': 1792, '龍': 1793, '！': 1794, '，': 1795, '－': 1796, '：': 1797, '？': 1798}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "encoder shape:\n",
      "(2000, 163, 71)\n",
      "\n",
      "decoder input shape:\n",
      "(2000, 46, 1799)\n",
      "\n",
      "decoder target shape:\n",
      "(2000, 46, 1799)\n",
      "\n",
      "encoder data:\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "decoder input data:\n",
      "[[[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "decoder target data:\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "print(\"\\ninput index:\")\n",
    "print(input_token_index)\n",
    "\n",
    "print(\"\\ntarget index:\")\n",
    "print(target_token_index)\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "\n",
    "print(\"\\nencoder shape:\")\n",
    "print(encoder_input_data.shape)\n",
    "print(\"\\ndecoder input shape:\")\n",
    "print(decoder_input_data.shape)\n",
    "print(\"\\ndecoder target shape:\")\n",
    "print(decoder_target_data.shape)\n",
    "            \n",
    "print(\"\\nencoder data:\")\n",
    "print(encoder_input_data[-2:])\n",
    "print(\"\\ndecoder input data:\")\n",
    "print(decoder_input_data[-2:])\n",
    "print(\"\\ndecoder target data:\")\n",
    "print(decoder_target_data[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302585c0",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "* We discard `encoder_outputs` and only keep the states (`state_h`, `state_c`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0761dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 04:55:01.379556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-18 04:55:01.383911: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-18 04:55:01.384109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7ecf76a70477): /proc/driver/nvidia/version does not exist\n",
      "2023-03-18 04:55:01.395538: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='lstm/PartitionedCall:2', description=\"created by layer 'lstm'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='lstm/PartitionedCall:3', description=\"created by layer 'lstm'\")\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "print(state_h)\n",
    "print(state_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ebf5e",
   "metadata": {},
   "source": [
    "# Decoder\n",
    "* Set up the decoder, using `encoder_states` as initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7acee820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, None, 1799), dtype=tf.float32, name=None), name='dense/Softmax:0', description=\"created by layer 'dense'\")\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "print(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0305b683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 71)]   0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, 1799)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 128),        102400      ['input_1[0][0]']                \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 128),  987136      ['input_2[0][0]',                \n",
      "                                 (None, 128),                     'lstm[0][1]',                   \n",
      "                                 (None, 128)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 1799)   232071      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,321,607\n",
      "Trainable params: 1,321,607\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "879aa6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 04:55:03.531915: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 529625600 exceeds 10% of free system memory.\n",
      "2023-03-18 04:55:04.808617: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 529625600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "100/100 [==============================] - 42s 354ms/step - loss: 1.5769 - val_loss: 1.3569\n",
      "Epoch 2/35\n",
      "100/100 [==============================] - 32s 317ms/step - loss: 1.4156 - val_loss: 1.3341\n",
      "Epoch 3/35\n",
      "100/100 [==============================] - 33s 330ms/step - loss: 1.3983 - val_loss: 1.3288\n",
      "Epoch 4/35\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 1.3887 - val_loss: 1.3254\n",
      "Epoch 5/35\n",
      "100/100 [==============================] - 36s 360ms/step - loss: 1.3822 - val_loss: 1.3104\n",
      "Epoch 6/35\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.3781 - val_loss: 1.3111\n",
      "Epoch 7/35\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 1.3753 - val_loss: 1.3063\n",
      "Epoch 8/35\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.3719 - val_loss: 1.3099\n",
      "Epoch 9/35\n",
      "100/100 [==============================] - 29s 294ms/step - loss: 1.3698 - val_loss: 1.3113\n",
      "Epoch 10/35\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 1.3669 - val_loss: 1.3086\n",
      "Epoch 11/35\n",
      "100/100 [==============================] - 34s 336ms/step - loss: 1.3641 - val_loss: 1.3071\n",
      "Epoch 12/35\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 1.3606 - val_loss: 1.2983\n",
      "Epoch 13/35\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.3565 - val_loss: 1.3078\n",
      "Epoch 14/35\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 1.3544 - val_loss: 1.2922\n",
      "Epoch 15/35\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 1.3499 - val_loss: 1.3063\n",
      "Epoch 16/35\n",
      "100/100 [==============================] - 47s 468ms/step - loss: 1.3472 - val_loss: 1.3075\n",
      "Epoch 17/35\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 1.3437 - val_loss: 1.2849\n",
      "Epoch 18/35\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 1.3395 - val_loss: 1.2953\n",
      "Epoch 19/35\n",
      "100/100 [==============================] - 31s 310ms/step - loss: 1.3354 - val_loss: 1.2723\n",
      "Epoch 20/35\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 1.3336 - val_loss: 1.2850\n",
      "Epoch 21/35\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 1.3292 - val_loss: 1.2817\n",
      "Epoch 22/35\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 1.3263 - val_loss: 1.2771\n",
      "Epoch 23/35\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 1.3235 - val_loss: 1.2820\n",
      "Epoch 24/35\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 1.3212 - val_loss: 1.2737\n",
      "Epoch 25/35\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.3178 - val_loss: 1.2726\n",
      "Epoch 26/35\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 1.3161 - val_loss: 1.2720\n",
      "Epoch 27/35\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.3145 - val_loss: 1.2707\n",
      "Epoch 28/35\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.3126 - val_loss: 1.2695\n",
      "Epoch 29/35\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 1.3098 - val_loss: 1.2709\n",
      "Epoch 30/35\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 1.3099 - val_loss: 1.2707\n",
      "Epoch 31/35\n",
      "100/100 [==============================] - 30s 298ms/step - loss: 1.3090 - val_loss: 1.2671\n",
      "Epoch 32/35\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.3074 - val_loss: 1.2680\n",
      "Epoch 33/35\n",
      "100/100 [==============================] - 30s 299ms/step - loss: 1.3045 - val_loss: 1.2660\n",
      "Epoch 34/35\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.3034 - val_loss: 1.2677\n",
      "Epoch 35/35\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 1.3032 - val_loss: 1.2658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05749b57d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb65471a",
   "metadata": {},
   "source": [
    "# inference mode (sampling)\n",
    "1. encode input and retrieve initial decoder state\n",
    "2. run one step of decoder with this initial state and a \"start of sequence\" token as target. Output will be the next target token\n",
    "3. Repeat with the current target token and current states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3e0b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c4e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc923b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 796ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "-\n",
      "Input sentence: Dad bought me a camera.\n",
      "Decoded sentence: 我姆有了了。\n",
      "\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "-\n",
      "Input sentence: There's no way to win.\n",
      "Decoded sentence: 我姆有了了。\n",
      "\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "-\n",
      "Input sentence: They rescued the boy from drowning.\n",
      "Decoded sentence: 我姆有了了。\n",
      "\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "-\n",
      "Input sentence: Tom isn't doing what he's supposed to be doing.\n",
      "Decoded sentence: 我姆有了了。\n",
      "\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "-\n",
      "Input sentence: When he retired, his son took over the business.\n",
      "Decoded sentence: 我姆有了了。\n",
      "\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "-\n",
      "Input sentence: Tom swims very fast.\n",
      "Decoded sentence: 我姆有了了。\n",
      "\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "-\n",
      "Input sentence: Do you know the concert schedule of London Symphony Orchestra?\n",
      "Decoded sentence: 我姆有了了。\n",
      "\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "-\n",
      "Input sentence: I do not know whether to accept or to refuse.\n",
      "Decoded sentence: 我姆有了了。\n",
      "\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "-\n",
      "Input sentence: Come if you can.\n",
      "Decoded sentence: 我姆有了了。\n",
      "\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "-\n",
      "Input sentence: Can you just please go?\n",
      "Decoded sentence: 我姆有了了。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(10):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8afed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
