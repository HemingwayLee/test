{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1cf075c",
   "metadata": {},
   "source": [
    "# There are some tips to learn\n",
    "## It is actually harder to learn compare to vanilla seq2seq\n",
    "* Add dropout\n",
    "  * because we are adding some more layers\n",
    "* Remove `initial_state=hidden`, get all information purely from attention layers\n",
    "* Add `clipnorm`\n",
    "* Change `learning_rate` is the most important thing\n",
    "* Add masks to AdditiveAttention\n",
    "  * If we have mask, it will learn better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2900ccf",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "* After I training the seq2seq model with different `flavors` and `options`, all those smaller tiny changes did help.\n",
    "  * If there is NO model just learn it anyway eventually, most of the time, the model just doesn't learn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21042544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrowdFlowerAnnotations.txt  Flickr8k.token.txt\t       machine_translation\r\n",
      "ExpertAnnotations.txt\t    Flickr_8k.devImages.txt    readme.txt\r\n",
      "Flicker8k_smaller\t    Flickr_8k.testImages.txt\r\n",
      "Flickr8k.lemma.token.txt    Flickr_8k.trainImages.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f989fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in /usr/local/lib/python3.7/site-packages (0.42.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fedb172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 10:31:13.491518: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-06-23 10:31:13.491636: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.231 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2000\n",
      "Number of unique input tokens: 2198\n",
      "Number of unique output tokens: 3211\n",
      "Max sequence length for inputs: 32\n",
      "Max sequence length for outputs: 32\n",
      "\n",
      "input data set:\n",
      "[['keep', 'off', 'the', 'grass'], ['mom', 'is', 'getting', 'dinner', 'ready'], [\"let's\", 'play', 'soccer'], ['tom', \"can't\", 'go', 'home', 'until', 'after', '2:30'], ['i', 'will', 'wait', 'here', 'till', 'he', 'comes'], ['put', 'the', 'chair', 'in', 'front', 'of', 'the', 'desk'], ['a', 'cafeteria', 'is', 'a', 'self-service', 'style', 'restaurant'], ['tom', 'encouraged', 'his', 'son', 'to', 'study', 'french'], ['i', 'was', 'surprised', 'to', 'see', 'a', 'lion'], ['where', 'is', 'the', 'nearest', 'police', 'station']]\n",
      "\n",
      "target data set:\n",
      "[['\\t', '不要', '踩', '草地', '。', '\\n'], ['\\t', '媽媽', '快', '把', '晚餐', '準備', '好', '了', '。', '\\n'], ['\\t', '去', '踢足球', '吧', '。', '\\n'], ['\\t', '汤姆', '在', '2', '：', '30', '之后', '才能', '回家', '。', '\\n'], ['\\t', '我會', '在', '這裡', '等', '直到', '他來', '。', '\\n'], ['\\t', '把', '椅子', '放在', '桌子', '前面', '。', '\\n'], ['\\t', '自助餐', '廳', '是', '一種', '自助式', '的', '餐廳', '。', '\\n'], ['\\t', '汤姆', '鼓励', '他', '儿子', '学法语', '。', '\\n'], ['\\t', '我', '很', '驚訝', '竟然', '看到', '了', '獅子', '。', '\\n'], ['\\t', '最近', '的', '警察局', '在', '哪里', '？', '\\n']]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Layer, Dropout, Embedding\n",
    "import numpy as np\n",
    "import random\n",
    "import jieba\n",
    "\n",
    "batch_size = 16  \n",
    "epochs = 15  \n",
    "latent_dim = 128  # Latent dimensionality of the encoding space.\n",
    "num_samples = 2000  # Number of samples to train on.\n",
    "data_path = '../../data/machine_translation/cmn.txt'\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "# for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "for line in random.sample(lines, num_samples):\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    \n",
    "    # We use \"\\t\" as the \"start sequence\" and \"\\n\" as \"end sequence\"\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    \n",
    "    tmp = []\n",
    "    for token in input_text.split(\" \"):\n",
    "        token = token.replace(\",\", \"\").replace(\".\", \"\").replace(\"?\", \"\").lower()\n",
    "        tmp.append(token)\n",
    "        if token not in input_tokens:\n",
    "            input_tokens.add(token)\n",
    "    input_texts.append(tmp)\n",
    "    \n",
    "    tmp = []\n",
    "    for token in jieba.cut(target_text, cut_all=False):\n",
    "        tmp.append(token)\n",
    "        if token not in target_tokens:\n",
    "            target_tokens.add(token)\n",
    "    target_texts.append(tmp)\n",
    "\n",
    "input_tokens = list(input_tokens)\n",
    "target_tokens = list(target_tokens)\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "print(\"\\ninput data set:\")\n",
    "print(input_texts[:10])\n",
    "print(\"\\ntarget data set:\")\n",
    "print(target_texts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc89d239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input index:\n",
      "{'carry': 0, 'sending': 1, 'smell': 2, 'kilometers': 3, 'turning': 4, 'seeing': 5, 'men': 6, \"we'll\": 7, 'open': 8, 'kobe': 9, 'watched': 10, 'happy\"': 11, 'subject': 12, \"he's\": 13, 'memory': 14, 'experience': 15, 'discussed': 16, 'wet': 17, 'smile': 18, 'vacation': 19, 'greater': 20, 'realize': 21, 'respect': 22, 'supplies': 23, 'attended': 24, 'living': 25, 'ordinary': 26, 'chair': 27, 'six': 28, 'sitting': 29, 'greeted': 30, 'elephants': 31, 'thrilling': 32, 'girlfriend': 33, 'disaster': 34, 'changes': 35, 'rotten': 36, 'clothing': 37, 'committee': 38, 'competed': 39, 'disappoint': 40, 'worker': 41, 'work': 42, \"isn't\": 43, 'leaving': 44, 'confused': 45, 'twin': 46, 'tickets': 47, 'over': 48, 'otaru': 49, 'husband': 50, 'miss': 51, 'intruded': 52, 'fireworks': 53, 'email': 54, 'throat': 55, 'half': 56, 'pictures': 57, \"mozart's\": 58, 'color': 59, 'given': 60, 'cat': 61, 'today': 62, 'classroom': 63, 'delicious': 64, 'oil': 65, 'cake': 66, 'slowly': 67, 'boys': 68, 'trouble': 69, 'you': 70, 'hokkaido': 71, 'hire': 72, 'wherever': 73, 'register': 74, 'missing': 75, 'sounds': 76, 'filled': 77, 'fire': 78, 'affairs': 79, 'deaf': 80, 'ogai': 81, 'private': 82, 'it!': 83, 'publication': 84, 'it': 85, 'higher': 86, 'think': 87, 'completely': 88, 'restaurant': 89, 'theater': 90, 'papers': 91, 'keys': 92, 'bored': 93, 'born': 94, 'haircut': 95, 'thumb': 96, 'wept': 97, 'listening': 98, 'assembled': 99, 'warrant': 100, \"weren't\": 101, 'flowers': 102, 'using': 103, 'quite': 104, 'regular': 105, 'never': 106, 'stealing': 107, 'touched': 108, 'birthday': 109, 'ticket': 110, 'act': 111, 'stop': 112, 'less': 113, 'insisted': 114, 'recovered': 115, 'hate': 116, 'times': 117, 'case': 118, 'several': 119, 'items': 120, 'chapped': 121, 'back': 122, 'innocent': 123, 'pass': 124, 'island': 125, 'id': 126, 'daugther': 127, 'spanish': 128, 'accepted': 129, 'picked': 130, 'lake': 131, 'issue': 132, 'picking': 133, 'reasons': 134, 'sunflower': 135, 'zoo': 136, 'grave': 137, 'weight': 138, 'one': 139, 'thinking': 140, 'covered': 141, 'habit': 142, 'need': 143, 'hungry': 144, 'stomachache': 145, 'spell': 146, 'cost': 147, 'certainly': 148, 'offices': 149, 'rear': 150, 'airplane': 151, 'extremes': 152, 'mastering': 153, 'shame': 154, 'grabbed': 155, 'audience': 156, 'far': 157, 'shopping': 158, 'mild': 159, 'kissed': 160, 'deserted': 161, 'visited': 162, 'shy': 163, 'novel': 164, 'cell': 165, 'talk': 166, 'left': 167, 'ask': 168, 'figure': 169, 'disturbed': 170, 'adjective': 171, 'pretty': 172, 'walks': 173, 'keller': 174, 'burst': 175, 'calm': 176, 'guys': 177, 'secretive': 178, 'needs': 179, \"tom's\": 180, 'our': 181, 'journalist': 182, 'english': 183, 'expensive': 184, 'oranges': 185, 'warm': 186, 'pretended': 187, 'better': 188, 'arrived': 189, 'fresh': 190, 'minutes': 191, 'weekend': 192, 'man': 193, 'hang': 194, 'shot': 195, \"couldn't\": 196, 'since': 197, 'talking': 198, 'kelly': 199, 'related': 200, 'climbing': 201, 'bother': 202, 'something': 203, 'walk': 204, 'brother': 205, 'suggest': 206, 'lady': 207, 'manager': 208, 'favorite': 209, '$300': 210, 'too': 211, 'chocolate': 212, 'busy': 213, 'soccer': 214, 'pencil': 215, 'roller-skate': 216, 'cold': 217, 'supper': 218, 'some': 219, 'hawaii': 220, 'examination': 221, '\"where': 222, 'prefers': 223, 'mud': 224, 'really': 225, 'could': 226, 'satisfied': 227, 'woman': 228, 'pizza': 229, 'approval': 230, 'desk': 231, 'clearly': 232, 'forgotten': 233, 'milk': 234, 'right\"': 235, 'similar': 236, 'tried': 237, 'irregular': 238, 'hopes': 239, 'low': 240, 'photos': 241, 'fear': 242, 'photo': 243, 'worry': 244, 'what': 245, 'away!': 246, 'schedule': 247, 'anyone': 248, 'meet': 249, 'interesting': 250, 'hey': 251, 'blonde': 252, 'thoughts': 253, 'apartment': 254, 'immigrants': 255, 'aimed': 256, 'or': 257, 'energy': 258, 'lips': 259, '10': 260, 'detective': 261, 'dying': 262, 'recognized': 263, 'use': 264, 'festival': 265, 'heard': 266, 'solving': 267, 'hurry': 268, 'fools': 269, 'girl': 270, 'rest': 271, 'smoke': 272, 'cook': 273, 'swarm': 274, \"we're\": 275, 'its': 276, 'solve': 277, 'found': 278, 'person': 279, 'move': 280, 'wall': 281, \"man's\": 282, 'rain': 283, 'succeeded': 284, 'health': 285, 'matters': 286, 'without': 287, \"doesn't\": 288, 'locked': 289, 'optimistic': 290, 'look': 291, 'bullied': 292, 'numb': 293, 'digital': 294, 'latin': 295, 'direction': 296, 'banana': 297, 'entire': 298, 'late': 299, 'sister': 300, 'nurse': 301, 'dreams': 302, 'bad': 303, 'lot': 304, 'agree': 305, 'glanced': 306, 'stuck': 307, 'power': 308, 'feel': 309, 'swimming': 310, 'evening': 311, 'injured': 312, 'as': 313, 'soon': 314, 'thinks': 315, 'game': 316, 'being': 317, 'spectacular!': 318, 'reached': 319, 'hated': 320, 'common': 321, 'tired': 322, 'dating': 323, 'ten-minute': 324, 'greenhouse': 325, 'toilet': 326, 'until': 327, 'misunderstood': 328, 'view': 329, 'received': 330, 'free': 331, 'after': 332, 'castle': 333, 'salmon': 334, 'bygones': 335, 'box': 336, 'promises': 337, 'save': 338, 'dinner': 339, 'church': 340, 'guide': 341, \"what're\": 342, \"world's\": 343, 'century': 344, 'happen': 345, 'hakone': 346, 'unique': 347, 'opinion': 348, 'ship': 349, 'interfered': 350, 'noise': 351, 'phone': 352, 'alcoholic': 353, \"father's\": 354, 'forward': 355, 'forewarned': 356, 'rules': 357, 'shake': 358, 'strait': 359, 'bitterly': 360, 'along': 361, 'comes': 362, 'movies': 363, 'legs': 364, 'bank': 365, 'facts': 366, 'influenced': 367, 'illness': 368, 'distasteful': 369, 'take': 370, 'italy': 371, 'vitamins': 372, 'blew': 373, 'maybe': 374, 'ran': 375, 'lots': 376, 'largest': 377, 'mary': 378, 'hotel': 379, 'purse': 380, 'answer': 381, 'books': 382, 'published': 383, 'based': 384, 'retired': 385, 'pepper': 386, 'moment': 387, \"i'm\": 388, 'fun': 389, 'prettier': 390, 'article': 391, 'superiors': 392, 'side': 393, 'quiet': 394, 'report': 395, 'racket': 396, 'leave': 397, 'paper': 398, 'street': 399, 'british': 400, 'crowd': 401, 'medicine': 402, 'houses': 403, 'around': 404, 'stand': 405, 'relax': 406, 'coat': 407, 'liar': 408, 'request': 409, 'apology': 410, 'love': 411, '\"it\\'s': 412, 'hour': 413, 'animals': 414, 'come': 415, 'learn': 416, 'mother': 417, 'burns': 418, 'playfully': 419, 'roses': 420, 'large': 421, 'kilometres': 422, 'gone': 423, 'first': 424, 'shell': 425, 'generally': 426, 'whenever': 427, 'borrowed': 428, 'boss': 429, 'heavy': 430, 'yokohama': 431, 'walking': 432, 'letter': 433, 'son': 434, \"heroine's\": 435, 'due': 436, 'all': 437, 'money': 438, 'easily': 439, 'that': 440, 'popcorn': 441, 'sports': 442, 'shoulder': 443, 'families': 444, 'bath': 445, 'invented': 446, 'we': 447, 'suggestion': 448, 'thirsty': 449, 'slip': 450, 'mistake': 451, 'angels': 452, 'copy': 453, 'three': 454, \"wasn't\": 455, 'longing': 456, 'jar': 457, 'emergency': 458, 'gift': 459, 'voyage': 460, 'exams': 461, 'young': 462, 'embarrassed': 463, 'exhausted': 464, 'simplest': 465, 'hearing': 466, 'eggs': 467, 'intervene': 468, 'lower': 469, '100000': 470, 'job': 471, 'argument': 472, 'resides': 473, 'later': 474, 'moon': 475, 'ignoring': 476, 'club': 477, 'wearing': 478, 'mentally': 479, 'deeds': 480, 'cheap': 481, 'keeps': 482, 'listened': 483, 'graduate': 484, 'awful': 485, 'adorable': 486, 'makeup': 487, 'horse': 488, 'eye': 489, 'nothing': 490, 'forearmed': 491, 'band': 492, 'escaped': 493, 'chicago': 494, 'ceo': 495, 'unknown': 496, 'four': 497, 'fixed': 498, 'make': 499, 'suggestions': 500, 'so\"': 501, 'divided': 502, 'patience': 503, 'no': 504, 'task': 505, 'engine': 506, 'scenic': 507, 'teaching': 508, \"we've\": 509, 'leaves': 510, 'airport': 511, 'climb': 512, 'lately': 513, 'port': 514, 'lost': 515, 'ringtone': 516, 'form': 517, 'sons': 518, 'engineer': 519, 'acquainted': 520, 'asking': 521, 'step': 522, 'pie': 523, 'told': 524, 'suits': 525, 'actually': 526, 'went': 527, 'nothing\"': 528, 'ate': 529, 'mean': 530, 'passengers': 531, 'business': 532, 'blamed': 533, 'influence': 534, 'masters': 535, 'cloud': 536, 'important': 537, 'punished': 538, 'aside': 539, 'record': 540, 'wash': 541, 'stayed': 542, 'waited': 543, 'handkerchief': 544, 'respectful': 545, 'fine': 546, 'helped': 547, 'improve': 548, 'playing': 549, 'unwise': 550, 'die': 551, 'city': 552, 'called': 553, 'pianist': 554, 'news': 555, 'tread': 556, 'i': 557, 'wine': 558, 'beat': 559, 'stupid': 560, 'dance': 561, 'light': 562, 'twentieth': 563, 'point': 564, 'secret': 565, 'things': 566, 'strong': 567, 'month': 568, 'horses': 569, 'again': 570, 'physics': 571, 'discarded': 572, '\"is': 573, 'baggage': 574, 'fast': 575, 'airmail': 576, 'fill': 577, 'toy': 578, 'advised': 579, 'mechanic': 580, 'turned': 581, 'restroom': 582, 'hard': 583, 'downstairs': 584, 'idea!': 585, 'care!': 586, 'luggage': 587, 'reason': 588, 'soft': 589, 'betrays': 590, 'most': 591, 'horror': 592, 'did': 593, 'urge': 594, 'honorable': 595, 'alert': 596, 'she': 597, 'ntt': 598, 'polite': 599, 'likes': 600, 'hit': 601, 'punishes': 602, 'salary': 603, 'visit': 604, 'acknowledged': 605, 'safe': 606, 'truck': 607, \"hadn't\": 608, 'black': 609, 'gang': 610, 'near': 611, 'won': 612, 'apart': 613, 'adjust': 614, 'students': 615, 'workday': 616, 'shuffle': 617, 'acted': 618, 'boat': 619, 'disheveled': 620, 'spring': 621, 'operation': 622, 'depends': 623, 'tears': 624, 'according': 625, 'marry': 626, 'amateur': 627, 'explain': 628, 'forehead': 629, 'probability': 630, 'chance': 631, 'many': 632, 'czech': 633, 'capital': 634, 'wrote': 635, 'countries': 636, 'more': 637, 'scraped': 638, \"i'd\": 639, 'let': 640, 'ourselves': 641, 'fingers': 642, 'spray': 643, 'daughter': 644, 'wears': 645, 'railroad': 646, 'through': 647, 'pronunciation': 648, 'you!': 649, 'souls': 650, 'practical': 651, 'diet': 652, 'fruit': 653, 'convinced': 654, 'driving': 655, 'golf': 656, 'why': 657, 'country': 658, \"what'll\": 659, 'canada': 660, 'learning': 661, 'call': 662, 'so': 663, 'memories': 664, 'lessons': 665, 'seem': 666, 'bucket': 667, 'father': 668, 'closed': 669, 'throw': 670, 'angry': 671, 'agenda': 672, 'holiday': 673, 'follows': 674, 'fighting': 675, 'bench': 676, 'bit': 677, 'windy': 678, 'vase': 679, 'learned': 680, 'imagination': 681, 'forgetful': 682, 'doctor': 683, \"you're\": 684, 'both': 685, 'venice': 686, 'prize': 687, 'lunch': 688, 'leads': 689, 'suddenly': 690, 'handed': 691, 'privately': 692, 'reach': 693, 'same': 694, 'set': 695, 'monopoly': 696, '2:30': 697, 'here': 698, 'treatment': 699, 'dangerous': 700, 'peace': 701, 'drama': 702, 'foreigner': 703, 'singer': 704, 'vienna': 705, 'monkey': 706, 'certain': 707, 'factory': 708, 'key': 709, 'white': 710, 'absolutely': 711, 'war': 712, 'ghosts': 713, '15': 714, 'if': 715, 'doing': 716, 'carefully': 717, \"they're\": 718, 'children': 719, 'spilled': 720, '12': 721, 'corner': 722, 'puzzled': 723, 'eyesight': 724, 'sense': 725, 'value': 726, 'lets': 727, 'storm': 728, 'earthquake': 729, 'must': 730, 'runner': 731, 'thanks': 732, 'afraid': 733, 'pen': 734, 'guitar': 735, 'to': 736, 'terms': 737, 'stock': 738, 'chat': 739, 'red': 740, 'pain': 741, 'listen': 742, 'announced': 743, 'uncle': 744, 'india': 745, 'questions': 746, 'train': 747, 'foot': 748, 'program': 749, 'follow': 750, '\"yes': 751, 'sentence': 752, 'tell': 753, 'depending': 754, 'earlier': 755, 'sleepy': 756, 'camping': 757, 'moon-viewing': 758, 'just': 759, 'starts': 760, 'available': 761, 'orange': 762, 'trains': 763, 'inside': 764, 'bicycle': 765, 'a': 766, 'underpants': 767, 'slow': 768, 'feeling': 769, 'richer': 770, 'type': 771, 'like': 772, 'few': 773, 'parents': 774, 'skeleton': 775, 'worse': 776, 'easygoing': 777, 'china': 778, 'ever': 779, 'across': 780, 'flows': 781, 'kitchen': 782, 'bread': 783, 'speaking': 784, 'have': 785, 'whole': 786, 'cried': 787, 'unpleasant': 788, 'skis': 789, \"children's\": 790, 'missed': 791, 'numbers': 792, 'responsibilities': 793, 'apologize': 794, 'someone': 795, 'close': 796, 'plunged': 797, 'gave': 798, 'whatever': 799, 'immediately': 800, 'yours': 801, 'quick': 802, 'blouse': 803, 'adjoins': 804, 'melons': 805, 'elated': 806, 'increase': 807, 'prepared': 808, 'high': 809, 'tomorrow': 810, 'plain': 811, 'teachers': 812, 'death': 813, 'closets': 814, 'security': 815, 'university': 816, 'finish': 817, 'wool': 818, '\"i\\'ve': 819, 'doorway': 820, 'the': 821, 'apple': 822, 'confidential': 823, 'neither': 824, 'quickly': 825, 'reflection': 826, 'overseas': 827, 'flunked': 828, 'grandson': 829, 'watching': 830, 'check': 831, 'trip': 832, 'sensitive': 833, 'lose': 834, 'idiot': 835, 'society': 836, 'firemen': 837, 'tables': 838, 'cards': 839, 'sunny': 840, 'eight-thirty': 841, 'made': 842, 'treated': 843, 'mine': 844, 'concert': 845, 'long': 846, 'occasional': 847, 'speakers': 848, 'office': 849, 'booth': 850, 'next': 851, 'badminton': 852, \"she'll\": 853, \"hasn't\": 854, 'remained': 855, 'first-year': 856, 'from': 857, 'word': 858, '1989': 859, 'glasses': 860, 'enjoyed': 861, 'american': 862, 'checked': 863, 'exact': 864, 'board': 865, 'nose': 866, 'initials': 867, 'sky': 868, 'police': 869, \"tomorrow's\": 870, 'acquire': 871, 'sell': 872, 'shooting': 873, 'physically': 874, 'passed': 875, 'them': 876, 'thing': 877, 'old': 878, 'democracy': 879, 'should': 880, 'junk': 881, 'bothering': 882, 'states': 883, 'carries': 884, 'once': 885, 'number': 886, 'grandpa': 887, 'ear': 888, 'exam': 889, '6:30': 890, 'skating': 891, 'watered': 892, 'apologetic': 893, 'laughed': 894, 'crashed': 895, 'extremely': 896, 'twins': 897, 'verbs': 898, 'again!': 899, 'anymore': 900, 'collection': 901, 'short': 902, 'switzerland': 903, 'juice': 904, '500': 905, 'parts': 906, 'pollution': 907, 'test': 908, 'lie': 909, 'anxious': 910, 'send': 911, 'usually': 912, 'lent': 913, 'swims': 914, 'consoling': 915, 'problems': 916, 'thames': 917, 'seems': 918, 'anything': 919, 'comic': 920, 'slept': 921, 'starving!': 922, 'wants': 923, 'belong': 924, 'early': 925, 'flag': 926, 'collecting': 927, 'charge': 928, 'pick': 929, 'married': 930, 'how': 931, 'foxes': 932, \"one's\": 933, 'salt': 934, 'heavier': 935, 'in-laws': 936, 'advertisements': 937, 'difficult': 938, 'music': 939, 'answered': 940, 'revolution': 941, 'then': 942, 'members': 943, 'arm': 944, 'hope': 945, 'women': 946, 'vague': 947, 'attend': 948, 'position': 949, 'be': 950, 'million': 951, 'ripped': 952, 'exercise': 953, 'kill': 954, 'thin': 955, 'osaka': 956, 'impossible': 957, 'confidence': 958, 'tree': 959, 'monday': 960, 'sweet': 961, 'jacket': 962, 'dessert': 963, 'consideration': 964, 'child': 965, 'lights': 966, 'one-way': 967, 'says': 968, 'compare': 969, 'onions': 970, 'applications': 971, 'life': 972, 'other': 973, 'killed': 974, 'progressing': 975, 'roared': 976, 'compromise': 977, 'household': 978, 'drinking': 979, 'speed': 980, 'spend': 981, 'possible': 982, 'drink': 983, 'beer': 984, 'yellow': 985, 'quit': 986, 'voice': 987, 'speech': 988, 'excuses': 989, 'turn': 990, 'tea': 991, '\"to': 992, 'drawing': 993, 'environmental': 994, 'united': 995, '\"she': 996, 'excuse': 997, 'on': 998, 'painted': 999, 'car': 1000, 'weed': 1001, 'lasted': 1002, 'only': 1003, 'said': 1004, 'blind': 1005, 'umpire': 1006, 'envied': 1007, 'great': 1008, 'tea\"': 1009, \"i'll\": 1010, 'final': 1011, 'there': 1012, 'huge': 1013, 'reads': 1014, 'banks': 1015, 'forever': 1016, 'fuji': 1017, 'hill': 1018, 'travel': 1019, 'discount': 1020, 'alone': 1021, 'cream': 1022, 'robbed': 1023, 'kiss': 1024, 'frighten': 1025, 'poor': 1026, 'fault': 1027, 'card': 1028, 'god': 1029, 'hamamatsu': 1030, 'information': 1031, 'horrible!': 1032, 'song': 1033, 'came': 1034, 'unanimously': 1035, 'hobby': 1036, 'twitter': 1037, 'plan': 1038, 'divorce': 1039, 'pulling': 1040, 'allow': 1041, 'pay': 1042, 'thirty': 1043, 'stands': 1044, 'buy': 1045, 'eaten': 1046, 'rude': 1047, 'adult': 1048, 'choose': 1049, 'classmates': 1050, 'shave': 1051, 'founded': 1052, 'everything': 1053, 'thank': 1054, 'waiting': 1055, 'almost': 1056, 'jaw': 1057, 'guilt': 1058, \"i've\": 1059, 'curry': 1060, 'trust': 1061, 'everybody': 1062, 'loudly': 1063, \"that's\": 1064, 'injury': 1065, 'flood': 1066, 'against': 1067, 'looked': 1068, 'dark': 1069, 'days': 1070, 'studied': 1071, 'works': 1072, 'puzzle': 1073, 'foreign': 1074, 'finds': 1075, 'honest': 1076, '20': 1077, 'door': 1078, 'table\"': 1079, 'suntan': 1080, 'anybody': 1081, 'interpreter': 1082, 'get': 1083, 'teacher': 1084, 'eighty': 1085, 'drop': 1086, 'somewhere': 1087, 'department': 1088, 'wear': 1089, 'ought': 1090, 'barely': 1091, 'wallet': 1092, 'junior': 1093, 'dare': 1094, 'frost': 1095, 'fifth-largest': 1096, 'would': 1097, 'dress': 1098, 'fruits': 1099, 'fascinated': 1100, 'clothes': 1101, 'selfish': 1102, 'trash': 1103, 'terrible': 1104, 'sent': 1105, 'tonight': 1106, 'drunken': 1107, 'way': 1108, 'of': 1109, 'proceed': 1110, 'complained': 1111, 'sails': 1112, 'pregnancy': 1113, 'opinions': 1114, 'story': 1115, 'friendship': 1116, 'loan': 1117, 'sore': 1118, 'mt': 1119, \"people's\": 1120, 'jam': 1121, 'material': 1122, 'kids': 1123, 'prices': 1124, 'window': 1125, 'while': 1126, 'timed': 1127, 'lock': 1128, 'lamp': 1129, 'movie': 1130, 'kitten': 1131, 'clear': 1132, 'begin': 1133, \"shouldn't\": 1134, 'meals': 1135, 'wake': 1136, 'paradise': 1137, 'mistook': 1138, 'blame': 1139, 'gibraltar': 1140, \"he'd\": 1141, 'search': 1142, 'producer': 1143, 'prairies': 1144, 'turns': 1145, 'started': 1146, 'worth': 1147, 'camera': 1148, 'native': 1149, 'coincide': 1150, 'reports': 1151, 'do': 1152, 'fall': 1153, 'return': 1154, 'faster': 1155, 'those': 1156, 'eleven': 1157, 'bird': 1158, 'souvenir': 1159, 'between': 1160, 'wrong': 1161, 'meetings': 1162, 'worried': 1163, 'stopped': 1164, 'liked': 1165, '\"why': 1166, 'whose': 1167, 'explorers': 1168, 'america': 1169, 'ten': 1170, 'japan': 1171, 'exist': 1172, 'can': 1173, 'borrow': 1174, 'guilty': 1175, 'borders': 1176, 'ice': 1177, \"won't\": 1178, 'welcome': 1179, 'ends': 1180, 'catch': 1181, 'week': 1182, 'happened': 1183, 'nests': 1184, 'mom': 1185, 'fifty': 1186, 'glue': 1187, 'taking': 1188, 'tissue': 1189, 'fair': 1190, 'opposed': 1191, 'mathematics': 1192, 'best': 1193, 'breath': 1194, 'experts': 1195, 'hilton': 1196, 'tragic': 1197, \"let's\": 1198, 'secretary': 1199, 'mirror': 1200, 'visits': 1201, 'autograph': 1202, \"earth's\": 1203, 'europe': 1204, 'hoping': 1205, 'habits': 1206, 'netherlands': 1207, 'flame': 1208, \"he'll\": 1209, 'trying': 1210, 'frightened': 1211, 'library': 1212, 'herself': 1213, 'school': 1214, 'holidays': 1215, 'bite': 1216, 'champion': 1217, 'does': 1218, 'stupidity': 1219, 'finding': 1220, 'big': 1221, 'student': 1222, 'garage': 1223, 'try': 1224, 'lacking': 1225, 'president': 1226, 'sets': 1227, 'everywhere': 1228, 'mistaken': 1229, 'lying': 1230, 'admission': 1231, 'go': 1232, 'computer': 1233, 'adding': 1234, 'ultrasound': 1235, \"girl's\": 1236, 'studying': 1237, 'expect': 1238, 'stole': 1239, 'dream': 1240, 'behind': 1241, 'supposed': 1242, 'spoke': 1243, 'everyone': 1244, 'politician': 1245, 'unsure': 1246, 'cup': 1247, 'umbrella': 1248, 'daughters': 1249, 'dog!': 1250, 'park': 1251, 'frightening': 1252, 'gets': 1253, 'deep': 1254, 'truth': 1255, 'procrastinating': 1256, 'evident': 1257, 'her': 1258, 'order': 1259, 'shirt': 1260, 'book': 1261, 'government': 1262, 'minute': 1263, 'become': 1264, 'five': 1265, 'decide': 1266, 'increasing': 1267, 'powder': 1268, 'accident': 1269, 'sleep': 1270, 'hurricane': 1271, 'education': 1272, 'cap': 1273, 'beware': 1274, 'barbeque': 1275, 'brought': 1276, 'means': 1277, 'looking': 1278, 'thirtieth': 1279, 'beholder': 1280, 'nor': 1281, \"you'll\": 1282, 'although': 1283, \"wouldn't\": 1284, 'calling': 1285, 'teaches': 1286, 'owe': 1287, 'thermometers': 1288, 'hair': 1289, 'weeks': 1290, \"there's\": 1291, 'matter': 1292, 'football': 1293, 'tune': 1294, 'rock': 1295, 'smoking': 1296, 'lives': 1297, 'growing': 1298, 'accustomed': 1299, 'christmas': 1300, \"who's\": 1301, 'meets': 1302, 'tooth': 1303, 'teens': 1304, 'solved': 1305, 'live': 1306, 'third': 1307, 'us': 1308, 'ashamed': 1309, 'warmed': 1310, 'thought': 1311, 'determination': 1312, 'station': 1313, 'item': 1314, 'singing': 1315, 'mind': 1316, 'was': 1317, 'stomach': 1318, 'major': 1319, 'friend': 1320, 'understand': 1321, 'jack': 1322, 'package': 1323, 'question': 1324, 'their': 1325, 'matches': 1326, '\"money': 1327, 'funeral': 1328, 'cry': 1329, 'barber\\'s\"': 1330, 'scarf': 1331, 'nobody': 1332, 'rice': 1333, \"teacher's\": 1334, 'speak': 1335, 'sleeping': 1336, 'down': 1337, 'going': 1338, 'by': 1339, 'korea': 1340, 'programs': 1341, 'together': 1342, 'unfit': 1343, 'egg': 1344, 'electrical': 1345, 'because': 1346, 'baseball': 1347, 'felt': 1348, 'rate': 1349, 'resign': 1350, 'kite': 1351, 'graceful': 1352, 'hens': 1353, 'off': 1354, 'asked': 1355, 'body': 1356, 'mistakes': 1357, 'success': 1358, 'poured': 1359, 'former': 1360, '\"i': 1361, 'level': 1362, 'cause': 1363, 'hi!': 1364, 'apologized': 1365, 'clock': 1366, 'help': 1367, 'panel': 1368, 'below': 1369, 'target': 1370, 'vietnam': 1371, 'till': 1372, \"it's\": 1373, 'making': 1374, 'tests': 1375, 'gun': 1376, 'end': 1377, 'lottery': 1378, 'caught': 1379, 'his': 1380, 'area': 1381, 'edo': 1382, 'plays': 1383, 'raining': 1384, 'ordered': 1385, 'instantly': 1386, 'rather': 1387, 'played': 1388, 'snow': 1389, 'fabulous': 1390, 'had': 1391, 'motorcycle': 1392, '3': 1393, 'control': 1394, 'match': 1395, 'efforts': 1396, 'orders': 1397, 'climate': 1398, 'meeting': 1399, 'hospital': 1400, 'dog': 1401, 'beautiful': 1402, 'carpentry': 1403, 'conform': 1404, 'potatoes': 1405, 'walked': 1406, 'himself': 1407, 'artificial': 1408, \"haven't\": 1409, 'is': 1410, 'always': 1411, 'crazy': 1412, 'pond': 1413, \"o'clock\": 1414, 'tokyo\"': 1415, 'road': 1416, 'languages': 1417, 'written': 1418, 'marketing': 1419, 'stolen': 1420, 'grows': 1421, 'arrive': 1422, 'stirred': 1423, 'admiring': 1424, 'surprised': 1425, 'tokyo': 1426, 'raw': 1427, 'blessed': 1428, 'jokes': 1429, 'sport': 1430, 'off\"': 1431, 'handing': 1432, 'history': 1433, 'facebook': 1434, 'than': 1435, 'knows': 1436, 'promised': 1437, 'watch': 1438, 'begins': 1439, 'intelligence': 1440, 'guarantee': 1441, 'owner': 1442, 'england': 1443, 'risk': 1444, 'worked': 1445, 'necessarily': 1446, 'longer': 1447, 'safety': 1448, 'very': 1449, 'wood': 1450, 'phone\"': 1451, 'directly': 1452, 'belongs': 1453, 'amazing': 1454, 'may': 1455, 'recently': 1456, 'hurts': 1457, 'comfortable': 1458, 'percent': 1459, 'cities': 1460, 'underestimated': 1461, 'fifteen': 1462, 'put': 1463, 'lecture': 1464, 'fish': 1465, 'activities': 1466, 'fell': 1467, 'australia': 1468, 'animal': 1469, 'cave': 1470, 'france': 1471, 'managed': 1472, 'moving': 1473, 'beach': 1474, 'absconded': 1475, 'army': 1476, 'gold': 1477, 'hundred': 1478, 'cruel': 1479, 'before': 1480, 'pregnant': 1481, 'hung': 1482, 'drive': 1483, 'bawling': 1484, 'aches': 1485, 'attention': 1486, 'night': 1487, 'boyfriend': 1488, 'frowned': 1489, 'furniture': 1490, 'stamps': 1491, 'meat': 1492, 'tells': 1493, 'careful': 1494, 'runs': 1495, 'unbelievable!': 1496, 'astonished': 1497, 'join': 1498, 'party': 1499, 'vegetables': 1500, 'remember': 1501, 'track': 1502, 'single': 1503, 'result': 1504, 'excited': 1505, 'me': 1506, 'notebook': 1507, 'difficulty': 1508, \"what's\": 1509, 'telephone': 1510, 'absent': 1511, 'breakfast': 1512, 'potato': 1513, 'became': 1514, 'tends': 1515, 'pleasure': 1516, 'eight': 1517, 'got': 1518, 'years': 1519, 'cutest': 1520, 'strange': 1521, 'lend': 1522, 'in': 1523, 'for': 1524, 'looks': 1525, 'saying': 1526, 'with': 1527, 'towns': 1528, 'duty': 1529, 'teaspoon': 1530, 'sits': 1531, 'miles': 1532, 'logic': 1533, 'liquid': 1534, 'summer': 1535, 'wreck': 1536, 'apples': 1537, 'standing': 1538, 'translated': 1539, 'parallel': 1540, 'showed': 1541, \"aren't\": 1542, 'independent': 1543, 'your': 1544, 'actor': 1545, 'interest': 1546, 'hurt': 1547, 'writing': 1548, 'and': 1549, 'idea': 1550, 'music\"': 1551, 'poet': 1552, 'buildings': 1553, 'luck': 1554, 'argued': 1555, 'ready': 1556, 'glad': 1557, 'full': 1558, 'poison': 1559, 'heavily': 1560, 'taxi': 1561, 'studies': 1562, 'architect': 1563, 'used': 1564, 'right': 1565, 'eyes': 1566, 'loved': 1567, 'fever': 1568, 'succeed': 1569, 'piano': 1570, 'shoot': 1571, 'relaxed': 1572, 'which': 1573, 'invited': 1574, 'dad': 1575, 'fastest': 1576, 'met': 1577, 'cash': 1578, '\"so': 1579, 'rid': 1580, 'year': 1581, 'planet': 1582, 'plane': 1583, 'hemisphere': 1584, 'asleep': 1585, 'flower': 1586, 'enter': 1587, 'serve': 1588, 'shoes': 1589, 'practiced': 1590, 'shut': 1591, 'rented': 1592, 'knowledge': 1593, 'prevented': 1594, 'took': 1595, 'afternoon': 1596, 'well': 1597, '10%': 1598, 'sleeves': 1599, 'shining': 1600, 'figured': 1601, 'last': 1602, 'kind': 1603, '1988': 1604, 'paris': 1605, 'are': 1606, 'still': 1607, 'believe': 1608, 'beckoned': 1609, 'birds': 1610, 'tenth': 1611, 'advice': 1612, 'protection': 1613, 'they': 1614, 'tendency': 1615, 'village': 1616, 'head': 1617, 'please': 1618, 'any': 1619, 'wishes': 1620, 'homework': 1621, 'bags': 1622, 'differ': 1623, 'second': 1624, 'patient': 1625, 'bottle': 1626, 'graduated': 1627, 'front': 1628, \"you've\": 1629, 'tigers': 1630, 'strawberries': 1631, 'grow': 1632, 'member': 1633, 'wife': 1634, 'plenty': 1635, 'dusts': 1636, 'class': 1637, 'statement': 1638, 'cannot': 1639, 'grass': 1640, 'am': 1641, \"that'll\": 1642, 'instrumental': 1643, 'chips': 1644, 'family': 1645, 'good': 1646, 'paying': 1647, 'built': 1648, 'not': 1649, 'style': 1650, 'whisky': 1651, 'expert': 1652, 'were': 1653, 'passport': 1654, 'brothers': 1655, 'either': 1656, 'beauty': 1657, 'friendly': 1658, 'difference': 1659, 'two': 1660, 'me!': 1661, 'conference': 1662, 'ago': 1663, 'want': 1664, 'fundamental': 1665, 'shadow': 1666, 'okay': 1667, 'abroad': 1668, 'bend': 1669, 'washed': 1670, 'happy': 1671, 'violin': 1672, 'advance': 1673, 'into': 1674, \"everyone's\": 1675, 'special': 1676, 'taught': 1677, 'changed': 1678, 'hopefully': 1679, 'originally': 1680, 'speaker': 1681, 'decided': 1682, 'unusual': 1683, 'temper': 1684, 'translate': 1685, 'dictionary': 1686, 'mix': 1687, 'reservation': 1688, 'seasons': 1689, 'politics': 1690, 'overeat': 1691, 'emotions': 1692, 'spent': 1693, 'halloween': 1694, 'boston': 1695, 'consult': 1696, 'responsible': 1697, 'shanghai': 1698, 'vacant': 1699, 'folded': 1700, 'nearest': 1701, \"should've\": 1702, 'permission': 1703, 'background': 1704, 'takes': 1705, 'resourceful': 1706, 'seldom': 1707, 'even': 1708, 'carried': 1709, 'start': 1710, 'alcohol': 1711, 'prophecy': 1712, 'crush': 1713, 'ufo': 1714, 'philosophy': 1715, \"book's\": 1716, 'accepting': 1717, 'under': 1718, 'served': 1719, 'riding': 1720, \"where's\": 1721, 'traffic': 1722, 'swimmers': 1723, 'fluently': 1724, 'boy': 1725, 'house': 1726, 'rumor': 1727, 'survive': 1728, 'steak': 1729, 'cd': 1730, 'swim': 1731, 'unavoidable': 1732, 'up': 1733, '\"would': 1734, 'spoken': 1735, 'writers': 1736, 'goes': 1737, 'credit': 1738, 'i\"': 1739, 'offer': 1740, 'older': 1741, 'discovered': 1742, 'principal': 1743, 'who': 1744, 'world': 1745, 'arrested': 1746, 'sorry': 1747, 'enjoy': 1748, 'morning': 1749, 'sure': 1750, 'tv': 1751, 'having': 1752, 'jump': 1753, 'february': 1754, 'nervous': 1755, 'songs': 1756, 'alarm': 1757, 'twice': 1758, 'relieved': 1759, 'new': 1760, 'flour': 1761, 'accused': 1762, 'flipped': 1763, 'fail': 1764, 'lighter': 1765, 'snows': 1766, 'awfully': 1767, 'french': 1768, 'shirts': 1769, 'has': 1770, 'continued': 1771, 'enough': 1772, 'likely': 1773, 'months': 1774, 'bookstore': 1775, 'touch': 1776, 'sing': 1777, 'pinched': 1778, 'garden': 1779, 'section': 1780, 'nine': 1781, 'unnecessary': 1782, 'slice': 1783, 'healthy': 1784, 'reading': 1785, 'puppy': 1786, 'subway': 1787, 'eat': 1788, 'windmill': 1789, 'lift': 1790, 'probably': 1791, 'shape': 1792, 'express': 1793, 'pair': 1794, 'might': 1795, 'working': 1796, 'cleaned': 1797, 'an': 1798, 'sound': 1799, 'broken': 1800, 'strict': 1801, 'explosion': 1802, 'robbery': 1803, 'discuss': 1804, 'relevant': 1805, 'language': 1806, \"friend's\": 1807, 'easier': 1808, 'running': 1809, 'needed': 1810, 'drug': 1811, 'mark': 1812, 'change': 1813, 'away': 1814, 'bus': 1815, 'often': 1816, 'quantities': 1817, 'cut': 1818, 'location': 1819, 'pilot': 1820, 'all!': 1821, 'mad': 1822, 'delayed': 1823, 'examined': 1824, 'seine': 1825, 'pool': 1826, 'german': 1827, 'knopfler': 1828, 'fishing': 1829, 'hook': 1830, 'locate': 1831, 'show': 1832, 'wonder': 1833, 'service': 1834, 'tennis': 1835, 'quoted': 1836, 'threw': 1837, 'exchange': 1838, 'grandfather': 1839, 'interested': 1840, 'where': 1841, 'scary': 1842, 'gifted': 1843, 'hours': 1844, \"didn't\": 1845, \"they've\": 1846, 'friends': 1847, 'controversial': 1848, 'oldest': 1849, 'during': 1850, 'cats': 1851, 'present': 1852, 'suitcase': 1853, 'positive': 1854, 'captivate': 1855, 'been': 1856, 'rush': 1857, 'hear': 1858, 'erase': 1859, 'noun': 1860, 'am!': 1861, 'teeth': 1862, 'home': 1863, 'know': 1864, 'myself': 1865, 'yourself': 1866, 'skirt': 1867, 'leaning': 1868, '100': 1869, 'store': 1870, 'wealth': 1871, 'appoint': 1872, 'tallest': 1873, 'kept': 1874, 'when': 1875, 'at': 1876, 'every': 1877, 'rich': 1878, 'dumb': 1879, 'each': 1880, 'dieting': 1881, 'forgot': 1882, 'speaks': 1883, 'york': 1884, 'but': 1885, 'seen': 1886, 'woke': 1887, 'floor': 1888, 'volleyball': 1889, 'london': 1890, 'interfere': 1891, 'giving': 1892, 'overtime': 1893, 'nice': 1894, 'ceiling': 1895, 'batteries': 1896, 'poker': 1897, \"you'd\": 1898, 'people': 1899, 'company': 1900, 'ended': 1901, 'dining': 1902, 'please\"': 1903, 'unlikely': 1904, 'play': 1905, 'majored': 1906, 'small': 1907, 'networks': 1908, 'sun': 1909, 'roof': 1910, 'struck': 1911, 'pieces': 1912, 'sulfur': 1913, 'own': 1914, 'pants': 1915, 'radio': 1916, 'able': 1917, 'flash': 1918, 'sat': 1919, 'eligible': 1920, 'sea': 1921, 'bring': 1922, 'hot': 1923, 'loses': 1924, 'skate': 1925, 'snowing': 1926, 'win': 1927, 'sir': 1928, 'another': 1929, 'wanted': 1930, 'seats': 1931, 'been\"': 1932, 'find': 1933, 'sometimes': 1934, 'sunday': 1935, 'afford': 1936, 'finally': 1937, 'encouraged': 1938, 'risks': 1939, 'easy': 1940, 'cookies': 1941, 'rome': 1942, 'ahead': 1943, 'cafeteria': 1944, 'temperature': 1945, 'planning': 1946, 'international': 1947, 'currently': 1948, 'build': 1949, 'ease': 1950, 'will': 1951, 'makes': 1952, 'materials': 1953, 'arguing': 1954, 'name': 1955, 'smart': 1956, 'neatly': 1957, 'college': 1958, 'stops': 1959, 'bought': 1960, 'tall': 1961, 'alive': 1962, 'cool': 1963, 'computers': 1964, 'mountaineering': 1965, 'table': 1966, 'bringing': 1967, 'wonderful': 1968, 'chinese': 1969, 'source': 1970, 'about': 1971, 'wish': 1972, 'trees': 1973, 'science': 1974, 'author': 1975, 'glared': 1976, 'saw': 1977, 'economy': 1978, 'coming': 1979, 'doctor\"': 1980, 'awake': 1981, 'mars': 1982, 'write': 1983, 'ugly': 1984, 'italians': 1985, 'swam': 1986, 'race': 1987, 'he': 1988, 'equal': 1989, 'dollars': 1990, 'price': 1991, 'classical': 1992, 'seven': 1993, 'others': 1994, 'coffee': 1995, 'parties': 1996, 'study': 1997, 'green': 1998, 'policeman': 1999, 'winter': 2000, 'saddled': 2001, 'sick': 2002, 'magazine': 2003, 'dressed': 2004, 'laugh': 2005, 'already': 2006, 'yet': 2007, 'theory': 2008, 'valuable': 2009, \"uncle's\": 2010, 'northern': 2011, 'quarreling': 2012, 'sight': 2013, 'such': 2014, 'true': 2015, \"don't\": 2016, 'newspaper': 2017, 'knew': 2018, 'real': 2019, 'rooms': 2020, 'coal': 2021, 'stone': 2022, 'picture': 2023, 'translating': 2024, 'meaning': 2025, 'attacked': 2026, \"can't\": 2027, 'place': 2028, 'dived': 2029, 'lion': 2030, 'shattered': 2031, 'bars': 2032, 'achieved': 2033, 'foundation': 2034, 'stay': 2035, 'period': 2036, 'say': 2037, 'silly': 2038, \"mary's\": 2039, 'else': 2040, 'community': 2041, '5': 2042, 'breathe': 2043, 'gentleman': 2044, \"professor's\": 2045, 'much': 2046, 'cousin': 2047, 'gate': 2048, 'died': 2049, 'room': 2050, 'breathing': 2051, 'population': 2052, 'forced': 2053, 'guy': 2054, \"phone's\": 2055, 'worst': 2056, 'appears': 2057, 'him': 2058, 'yesterday': 2059, 'handwriting': 2060, 'explanation': 2061, 'fireplace': 2062, 'part': 2063, 'helen': 2064, 'drunk': 2065, 'patio': 2066, 'share': 2067, 'grandmother': 2068, 'wait': 2069, 'exaggerate': 2070, '455': 2071, 'telling': 2072, 'dogs': 2073, 'cart': 2074, 'accidents': 2075, 'repaired': 2076, 'prefer': 2077, 'satellite': 2078, 'boots': 2079, 'care': 2080, 'noisy': 2081, 'handy': 2082, 'dust': 2083, 'talks': 2084, 'sung': 2085, 'this': 2086, 'loves': 2087, 'mood': 2088, 'veteran': 2089, 'japan\"': 2090, 'handsome': 2091, 'jealous': 2092, 'continue': 2093, 'blushing': 2094, 'eating': 2095, 'traveled': 2096, 'guests': 2097, 'post': 2098, 'ibm': 2099, 'age': 2100, 'page': 2101, 'hornets': 2102, 'river': 2103, 'pin': 2104, 'tom': 2105, 'see': 2106, 'whether': 2107, 'future': 2108, 'noon': 2109, 'facing': 2110, 'bag': 2111, 'contains': 2112, 'blue': 2113, 'associate': 2114, 'my': 2115, 'give': 2116, 'differently': 2117, 'taken': 2118, 'bridges': 2119, 'situation': 2120, 'shyly': 2121, 'little': 2122, 'industrial': 2123, 'above': 2124, 'food': 2125, 'diary': 2126, 'television': 2127, 'surrender': 2128, 'knocked': 2129, 'located': 2130, 'prison': 2131, 'appeared': 2132, '\"have': 2133, 'japanese': 2134, 'phoned': 2135, 'popular': 2136, 'luxuries': 2137, 'law': 2138, 'privacy': 2139, 'now': 2140, 'causing': 2141, 'squeezed': 2142, 'deny': 2143, 'out': 2144, 'bed': 2145, 'piece': 2146, 'tiny': 2147, 'earned': 2148, 'public': 2149, 'these': 2150, 'self-service': 2151, 'brown': 2152, 'day': 2153, 'aunt': 2154, 'water': 2155, 'weather': 2156, 'drank': 2157, 'except': 2158, 'wrist': 2159, 'preparing': 2160, 'harder': 2161, 'involves': 2162, 'done': 2163, 'shuttlecock': 2164, 'social': 2165, 'famous': 2166, 'expected': 2167, 'cancer': 2168, 'ai': 2169, 'zero': 2170, 'romantic': 2171, 'resting': 2172, 'younger': 2173, 'read': 2174, 'ball': 2175, 'time': 2176, 'getting': 2177, 'denied': 2178, 'baby': 2179, 'broke': 2180, 'keep': 2181, 'known': 2182, 'ships': 2183, 'finished': 2184, 'mountains': 2185, 'grateful': 2186, \"she's\": 2187, 'grade': 2188, 'problem': 2189, 'fired': 2190, 'hand': 2191, 'rushed': 2192, 'extra': 2193, 'dye': 2194, 'lived': 2195, 'thieves': 2196, 'kid': 2197}\n",
      "\n",
      "target index:\n",
      "{'到': 0, '國': 1, '持續': 2, '这点': 3, '那条': 4, '看待': 5, '丟了': 6, '代表': 7, '那盘': 8, '照相': 9, '哪来': 10, '总体': 11, '金钱': 12, '失去': 13, '該諮詢': 14, '母鸡': 15, '历史': 16, '我想講': 17, '所以': 18, '拍照片': 19, '駕駛': 20, '任何': 21, '留著': 22, '不怕死': 23, '厌倦': 24, '偶爾': 25, '这部': 26, '股票': 27, '海倫凱勒': 28, '举止': 29, '。': 30, '澡': 31, '我下': 32, '生意': 33, '不符': 34, '几分': 35, '以为': 36, '湖在': 37, '真相': 38, '鸡蛋': 39, '縮': 40, '此': 41, '钱财': 42, '極少數': 43, '国外': 44, '呼吸困难': 45, '一个男孩': 46, '厭煩': 47, '我母': 48, '該信': 49, '春天': 50, '场': 51, '父母': 52, '既往不咎': 53, '天气': 54, '起飛': 55, '人': 56, '學習': 57, '念': 58, '直接': 59, '橘子': 60, '固定': 61, '挣': 62, '每个': 63, '高興': 64, '赞同': 65, '不高興': 66, '过': 67, '寄': 68, '吧': 69, '本来': 70, '火撲滅': 71, '用来': 72, '這班': 73, '隨和': 74, '骸骨': 75, '花園裡': 76, '精神': 77, '摩托': 78, '誇張': 79, '草原': 80, '国家': 81, '月球': 82, '裡的': 83, '考试': 84, '雪地': 85, '能够': 86, '立刻': 87, '功课': 88, '考虑': 89, '查明': 90, '地點': 91, '逐字': 92, '臥病': 93, '委员会': 94, '报纸': 95, '記得': 96, '一周': 97, '斷': 98, '買': 99, '所有': 100, '正當': 101, '找到': 102, '杯': 103, '健康': 104, '父亲': 105, '父親': 106, '弄': 107, '过夜': 108, '海邊': 109, '超聲': 110, '歡迎': 111, '得主': 112, '偷錢': 113, '一雙': 114, '谁': 115, '賺': 116, '簽名': 117, '航行': 118, '華': 119, '信': 120, '九點': 121, '很快': 122, '借': 123, '多好': 124, '帶': 125, '鐘內': 126, '待遇': 127, '政府': 128, '强迫': 129, '小孩儿': 130, '話': 131, '我常': 132, '基于': 133, '忠告': 134, '遲到': 135, '难以置信': 136, '幸福': 137, '魚和紅酒': 138, '闆': 139, '一根': 140, '前進': 141, '靠近': 142, '退休': 143, '火柴': 144, '月': 145, '他來': 146, '直布羅陀': 147, '謎': 148, '赶上': 149, '錶': 150, '威士忌': 151, '时': 152, '宴會': 153, '樂趣': 154, '建': 155, '姊妹': 156, '舉起': 157, '二十': 158, '一輛': 159, '緊鄰': 160, '跳下来': 161, '安全': 162, '会议': 163, '进来': 164, '聲音': 165, '下個': 166, '淚流': 167, '湯姆喜': 168, '鞋子': 169, '不嫉妒': 170, '孩子': 171, '穿着': 172, '我繼續': 173, '三個': 174, '惊喜': 175, '往': 176, '记得': 177, '程度': 178, '他遊過': 179, '五點': 180, '跳入': 181, '煤炭': 182, '一種': 183, '三分': 184, '郵票': 185, '法国': 186, '這把': 187, '液體': 188, '為': 189, '比美': 190, '聚會': 191, '生氣': 192, '這不': 193, '寒酸': 194, '水裝滿': 195, '穿越': 196, '乘': 197, '他們': 198, '回應': 199, '财富': 200, '给予': 201, '起': 202, '必須': 203, '澳大利亚': 204, '光臨': 205, '饿': 206, '對面': 207, '驳回': 208, '没想': 209, '剪個頭': 210, '回家': 211, '小气': 212, '認出': 213, '每個': 214, '搭': 215, '手枪': 216, '似乎': 217, '白痴': 218, '再也': 219, '燃燒': 220, '写': 221, '莫扎特': 222, '這家': 223, '常识': 224, '随便': 225, '開': 226, '飛機': 227, '這是': 228, '金子': 229, '一片': 230, '頭': 231, '请': 232, '残忍': 233, '現金': 234, '耽擱': 235, '一匹': 236, '向': 237, '用': 238, '草莓': 239, '幫忙': 240, '唱歌': 241, '經驗': 242, '动物': 243, '力量': 244, '相同': 245, '将': 246, '湯姆像': 247, '我會永遠': 248, '入場費': 249, '盡': 250, '第一次': 251, '在家': 252, '诗人': 253, '普通': 254, '由': 255, '週將': 256, '騎馬': 257, '爬': 258, '那时': 259, '失明': 260, '多少': 261, '瞪': 262, '追': 263, '確定': 264, '影子': 265, '为什么': 266, '些': 267, '那邊': 268, '吃饭': 269, '付': 270, '先生': 271, '當這位': 272, '他將': 273, '看书': 274, '灰塵': 275, '意義': 276, '需要': 277, '轉晴': 278, '玩笑': 279, '換火車': 280, '運通': 281, '阿姨': 282, '已經': 283, '多吃点': 284, '老': 285, '恨': 286, '要些': 287, '哪个': 288, '有點': 289, '請求': 290, '這艘': 291, '脸红': 292, '遠': 293, '右臂': 294, '這場': 295, '打電話給': 296, '參加': 297, '間裡': 298, '意外': 299, '让开': 300, '衛生': 301, '右邊': 302, '遗嘱': 303, '新鲜事': 304, '石油': 305, '词典': 306, '不及格': 307, '分為': 308, '多大': 309, '等级': 310, '流经': 311, '手術': 312, '教堂': 313, '多': 314, '出现': 315, '石頭': 316, '私人': 317, '有个': 318, '湯姆時': 319, '失败': 320, '更': 321, '跟着': 322, '江戶': 323, '黃': 324, '這扇': 325, '洪水': 326, '全力': 327, '姓': 328, '級': 329, '漏': 330, '祖母': 331, '个': 332, '更勤些': 333, '面包': 334, '去世': 335, '加为好友': 336, '价格': 337, '这所': 338, '這些': 339, '長': 340, '副': 341, '者': 342, '睡': 343, '确定': 344, '电影': 345, '岛': 346, '滿面': 347, '常': 348, '遇到': 349, '钱包': 350, '電腦': 351, '主人': 352, '任务': 353, '小男孩': 354, '於': 355, '每天': 356, '祈盼': 357, '看看': 358, '心情': 359, '阳光': 360, '？': 361, '30': 362, '利益': 363, '不靠': 364, '不應': 365, '寄希望于': 366, '黄了': 367, '你好': 368, '撒謊': 369, '面': 370, '坚持': 371, '芝加哥': 372, '一步': 373, '不到': 374, '事实': 375, '横滨': 376, '夢': 377, '水稻': 378, '塞纳河': 379, '公眾': 380, '間': 381, '于': 382, '羽毛球': 383, '课上': 384, '结果': 385, '因酒': 386, '方式': 387, '这是': 388, '三片': 389, '家': 390, '身': 391, '气候': 392, '没法': 393, '真壞': 394, '东西': 395, '身上': 396, '富得': 397, '浪漫': 398, '打碎': 399, '他活': 400, '机场': 401, '無法': 402, '這麼': 403, '定下': 404, '湯姆會': 405, '貧窮': 406, '行星': 407, '慫恿': 408, '早飯': 409, '等等': 410, '10': 411, '天黑': 412, '不好': 413, '没': 414, '選手們': 415, '再往': 416, '日語': 417, '蘋果': 418, '小偷': 419, '否認': 420, '誤認': 421, '祝': 422, '工厂': 423, '收音': 424, '沿着': 425, '某人': 426, '能試': 427, '喜欢': 428, '取得': 429, '樽': 430, '六人': 431, '纪念品': 432, '著眉頭': 433, '明年': 434, '终生': 435, '影': 436, '阅读': 437, '有人': 438, '女士': 439, '最高': 440, '人数': 441, '敏感': 442, '八十': 443, '找': 444, '一棵树': 445, '布满': 446, '清洗': 447, '嘴': 448, '会员': 449, '出卖': 450, '替': 451, '电池': 452, '三个': 453, '老師': 454, '吸引': 455, '她化': 456, '湯姆給': 457, '最好': 458, '美國': 459, '产地': 460, '等到': 461, '希望': 462, '说话': 463, '晚上': 464, '他学': 465, '有些': 466, '真正': 467, '暗恋着': 468, '湯姆皺': 469, '秋天': 470, '裙子': 471, '回辦': 472, '这场': 473, '抽': 474, '麵': 475, '最美': 476, '来': 477, '无所谓': 478, '学好': 479, '時代賞': 480, '谈谈': 481, '去求': 482, '關於船': 483, '一年': 484, '以': 485, '借支': 486, '小': 487, '没关系': 488, '关于': 489, '重得': 490, '探险家': 491, '假装': 492, '安静': 493, '好了吗': 494, '过去': 495, '麻烦': 496, '两次': 497, '们': 498, '技師': 499, '昨晚': 500, '而': 501, '辛苦': 502, '足够': 503, '當時': 504, '今天下午': 505, '钢笔': 506, '下回': 507, '胃癌': 508, '公室': 509, '河對岸': 510, '跑': 511, '观点': 512, '計程車': 513, '玛丽': 514, '門邊': 515, '燈變': 516, '尊重': 517, '电影吧': 518, '中文': 519, '移民': 520, '一页': 521, '基礎': 522, '网络': 523, '投降': 524, '多一点': 525, '蓝色': 526, '聖': 527, '过会': 528, '不停': 529, '讨论': 530, '建筑师': 531, '褐色': 532, '衣櫥': 533, '很能': 534, '剛剛': 535, '波士': 536, '研究': 537, '名词': 538, '車開': 539, '語': 540, '因為': 541, '行程': 542, '無': 543, '今儿': 544, '准时': 545, '！': 546, '保暖': 547, '回': 548, '二月': 549, '开': 550, '邀': 551, '零度': 552, '乘客': 553, '董事会': 554, '咖啡': 555, '病': 556, '連針': 557, '一洗': 558, '客廳': 559, '欧洲': 560, '广播': 561, '对': 562, '哪儿': 563, '問題': 564, '带来': 565, '大': 566, '其他人': 567, '电脑': 568, '即': 569, '才': 570, '胃痛': 571, '髮': 572, '风车': 573, '相聚': 574, '保存': 575, '習慣': 576, '动词': 577, '感冒': 578, '壁爐': 579, '封信': 580, '隨意': 581, '女朋友': 582, '一分钟': 583, '美': 584, '不過': 585, '这歌': 586, '優美而聞名': 587, '得知': 588, '開的車': 589, '免費': 590, '这座': 591, '大楼': 592, '交通堵塞': 593, '流利': 594, '也': 595, '葡萄酒': 596, '早饭': 597, '一会儿': 598, '瓜': 599, '部门': 600, '不行': 601, '廚房裡': 602, '波士顿': 603, '還買': 604, '手指': 605, '這項': 606, '女': 607, '我租': 608, '榨': 609, '內褲': 610, '最快': 611, '過得': 612, '餓': 613, '演讲': 614, '沒有': 615, '價格': 616, '我病': 617, '他親': 618, '躲雨': 619, '殺': 620, '回答': 621, '這樣': 622, '不干': 623, '出門': 624, '下巴': 625, '邀請': 626, '錯誤': 627, '一大群': 628, '一座': 629, '強迫': 630, '蛋壳': 631, '修读': 632, '磕碎': 633, '友好': 634, '歌曲': 635, '我還': 636, '航空': 637, '穿著': 638, '愚人': 639, '一个': 640, '别的': 641, '它給': 642, '药会': 643, '很聰明': 644, '停下': 645, '老师': 646, '50': 647, '一个月': 648, '外国人': 649, '还是': 650, '不同': 651, '可愛的': 652, '单行道': 653, '携款': 654, '衬衫': 655, '維他': 656, '東京': 657, '犯': 658, '鬧鐘': 659, '养': 660, '钓鱼': 661, '多年': 662, '天花': 663, '电视': 664, '或许': 665, '信任': 666, '裡放': 667, '相機': 668, '常常': 669, '一定': 670, '出去': 671, '读': 672, '欣喜若狂': 673, '保护': 674, '怕': 675, '排球': 676, '兄妹': 677, '我誤': 678, '湯姆頭': 679, '這所學校': 680, '喝点': 681, '第一项': 682, '见到': 683, '發燒': 684, '比较': 685, '機會': 686, '作者': 687, '洞穴': 688, '回信': 689, '清楚': 690, '覺得': 691, '外': 692, '羞恥': 693, '們': 694, '一條': 695, '認識': 696, '懂': 697, '慢慢': 698, '這地區': 699, '過來': 700, '搭公車': 701, '放弃': 702, '說過': 703, '遠遠': 704, '他現': 705, '這本': 706, '給他': 707, '謝謝': 708, '体重': 709, '再见面': 710, '當點心': 711, '抱歉': 712, '號碼': 713, '伦敦': 714, '电视机': 715, '注意': 716, '充满活力': 717, '只有': 718, '襲擊': 719, '不像': 720, '房子': 721, '妹妹': 722, '天堂': 723, '記得給': 724, '机密': 725, '什么': 726, '贫穷': 727, '工作日': 728, '射击': 729, '麼': 730, '適合': 731, '事情': 732, '第三': 733, '\\t': 734, '火星': 735, '洗': 736, '牛奶': 737, '還是': 738, '过后': 739, '投入使用': 740, '说得好': 741, '同時': 742, '知識': 743, '一盆': 744, '我鎖': 745, '·': 746, '提前': 747, '都爛': 748, '有时': 749, '干': 750, '取决于': 751, '音樂會': 752, '灯': 753, '留下来': 754, '拉丁': 755, '图书馆': 756, '傻子': 757, '爸爸': 758, '出门': 759, '免': 760, '保持联系': 761, '認為': 762, '會議': 763, '学校': 764, '执行': 765, '講話': 766, '說明': 767, '马克': 768, '哪里': 769, '总裁': 770, '那件事': 771, '這家電': 772, '还有': 773, '搶': 774, '比馬鈴薯': 775, '聪明': 776, '應該': 777, '椅子': 778, '一样': 779, '摘花': 780, '哪一個': 781, '俱樂部': 782, '這': 783, '网球': 784, '床上': 785, '办法': 786, '同意': 787, '安靜到': 788, '鐘到': 789, '給我': 790, '湯姆': 791, '咬': 792, '医院': 793, '第二十': 794, '無法表達': 795, '云': 796, '只顾': 797, '购物': 798, '郵局': 799, '谈话': 800, '介入': 801, '第五': 802, '酒精': 803, '音乐': 804, '學遲': 805, '还': 806, '不读': 807, '劇社': 808, '约': 809, '海峽': 810, '我六點': 811, '完信': 812, '獨自度過': 813, '天下': 814, '学': 815, '欺负': 816, '把': 817, '過世': 818, '瘦': 819, '星期一': 820, '撞': 821, 'Mary': 822, '聚在一起': 823, '聊': 824, '学习': 825, '走得': 826, '衣服': 827, '三十': 828, '賣': 829, '美元': 830, '不必': 831, '湯姆應': 832, '其他': 833, '這位': 834, '加劲': 835, '吃點': 836, '允许': 837, '不合': 838, '裡種': 839, '方法': 840, '感受': 841, '我家': 842, '中午饭': 843, '忍受': 844, '五十岁': 845, '哲學': 846, '瑞士': 847, '成': 848, '真的': 849, '美味': 850, '放学': 851, '唯一': 852, '選擇': 853, '发音': 854, '兩顆': 855, '上学': 856, '没多久': 857, '事達成': 858, '喝酒': 859, '世纪': 860, '指示': 861, '中犯': 862, '製': 863, '讀': 864, '同学': 865, '兩個': 866, '湯姆住': 867, '图片': 868, '闻见': 869, '大病': 870, '酸': 871, '泥巴': 872, '畫是': 873, '任命': 874, '發現': 875, '母親': 876, '約': 877, '我無法': 878, '扔': 879, '）': 880, '熱門': 881, '前': 882, '惊恐': 883, '自私': 884, '昨天': 885, '石头': 886, '最大': 887, '年龄': 888, '或者': 889, '留在': 890, '一樣': 891, '手機': 892, '分歧': 893, '梦': 894, '看一遍': 895, '区别': 896, '機不': 897, '富士山': 898, '看見': 899, '本该': 900, '演講': 901, '完全同意': 902, '比賽將': 903, '周遊': 904, 'NTT': 905, '不': 906, '關門': 907, '时读': 908, '柳橙汁': 909, '寫信': 910, '大約': 911, '出国': 912, '废物': 913, '太': 914, '哪些': 915, '加入': 916, '数量': 917, '主修': 918, '地': 919, '几颗': 920, '借錢給': 921, '謝': 922, '打擾': 923, '吸烟': 924, '單獨': 925, '太陽': 926, '怎樣': 927, '法語': 928, '解释': 929, '跟我来': 930, '之間': 931, '英國': 932, '很帅': 933, '湯姆還': 934, '照': 935, '告终': 936, '去': 937, '怎么': 938, '飯': 939, '足球赛': 940, '花瓶': 941, '我该': 942, '壞': 943, '连衣裙': 944, '预定': 945, '共': 946, '这': 947, '速度': 948, '发现': 949, '牙': 950, '完全': 951, '火车站': 952, '出席会议': 953, '留灯': 954, '长期': 955, '幫': 956, '有意': 957, '热情': 958, '下星期': 959, '上司': 960, '侦探': 961, '女人': 962, '輸': 963, '要是': 964, '」': 965, '责任': 966, '許多': 967, '晚餐': 968, '你們還': 969, '前面': 970, '是因为': 971, '旗子': 972, '终于': 973, '舒服': 974, '高尔夫球': 975, '之中': 976, '植': 977, '上路': 978, '垃圾': 979, '認真地': 980, '谈': 981, '裤子': 982, '這支筆': 983, '闹钟': 984, '头发': 985, '一眼': 986, '比賽': 987, '不見': 988, '已': 989, '獨特': 990, '看得见': 991, '頓': 992, '兩': 993, '政治家': 994, '該': 995, '便宜': 996, '美圓': 997, '开始': 998, '越來': 999, '起来': 1000, '瑪麗會': 1001, '生子': 1002, 'Facebook': 1003, '可怕': 1004, '美國人': 1005, '书桌上': 1006, '鳥': 1007, '辞职': 1008, '米': 1009, '互帮互助': 1010, '一通': 1011, '用場': 1012, '很少': 1013, '男孩子': 1014, '公共': 1015, '应该': 1016, '打电话': 1017, '將來': 1018, '畏懼': 1019, '不可避免': 1020, '计划': 1021, '歷史': 1022, '打電話': 1023, '方向感': 1024, '着': 1025, '地上': 1026, '收音机': 1027, '情况': 1028, '受伤': 1029, '小时': 1030, '愛他': 1031, '會待': 1032, '部分': 1033, '他家': 1034, '成真': 1035, '貓和': 1036, '減肥': 1037, '逻辑': 1038, '信給': 1039, '完晚': 1040, '對': 1041, '天花板': 1042, '大麻': 1043, '轻松': 1044, '就行了': 1045, '一件': 1046, '下樓': 1047, '期待': 1048, '餐厅': 1049, '冷': 1050, '科比': 1051, '警惕': 1052, '加班': 1053, '记忆': 1054, '诚实': 1055, '成为': 1056, '完': 1057, '摸': 1058, '：': 1059, '就': 1060, '商量': 1061, '钢琴家': 1062, '第二天': 1063, '喝掉': 1064, '变糟': 1065, '无关紧要': 1066, '圣诞节': 1067, '戒煙': 1068, '卡車': 1069, '奇怪': 1070, '證': 1071, '那間': 1072, '球': 1073, '你家': 1074, '底下': 1075, '糟糕': 1076, '公寓': 1077, '发生': 1078, 'Twitter': 1079, '真特別': 1080, '我要': 1081, '幾點': 1082, '了解': 1083, '而已': 1084, '深思熟虑': 1085, '這個': 1086, '世界': 1087, '電影': 1088, '主意': 1089, '同一': 1090, '15': 1091, '一起': 1092, '句子': 1093, '你老': 1094, '拼': 1095, '新鮮': 1096, '丢脸': 1097, '棒球': 1098, '談論': 1099, '小猫': 1100, '12': 1101, '拍照': 1102, '急情': 1103, '刮起来': 1104, '起車': 1105, '健忘': 1106, '一段时间': 1107, '科目': 1108, '一本': 1109, '痛哭': 1110, '城堡': 1111, '保持': 1112, '000': 1113, '獨自去': 1114, '《': 1115, '太熱': 1116, '上衣': 1117, '匆忙': 1118, '那么': 1119, '课': 1120, '手': 1121, '相當': 1122, '有利': 1123, '辭職': 1124, '围巾': 1125, '增加': 1126, '工程': 1127, '六點': 1128, '一點兒': 1129, '教室': 1130, '年轻': 1131, '闭着': 1132, '每年': 1133, '乐观': 1134, '女主角': 1135, '事業': 1136, '想来': 1137, '害怕': 1138, '左转': 1139, '夾克': 1140, '说': 1141, '過頭': 1142, '自行': 1143, '电子邮件': 1144, '經常': 1145, '吵': 1146, '儿子': 1147, '吃過': 1148, '甜點': 1149, '上門': 1150, '游泳': 1151, '那話': 1152, '胆小': 1153, '允許': 1154, '无法': 1155, '生魚': 1156, '見過': 1157, '跟別': 1158, '拍': 1159, '休息': 1160, '啥': 1161, '承諾': 1162, '不生氣': 1163, '九折': 1164, '客人': 1165, '慢点': 1166, '這房': 1167, '好消息': 1168, '力所能及': 1169, '很大': 1170, '飞行员': 1171, '日本': 1172, '愛我': 1173, '瘋狂': 1174, '滿意': 1175, '体育运动': 1176, '北海道': 1177, '經在': 1178, '间': 1179, '朋友': 1180, '痠': 1181, '漂亮': 1182, '请问': 1183, '小女孩': 1184, '餡餅': 1185, '看來': 1186, '班上': 1187, '怎么样': 1188, '鮭魚': 1189, '房間': 1190, '冰上': 1191, '梦想': 1192, '大家': 1193, '絶': 1194, '大該': 1195, '額頭': 1196, '游得': 1197, '有点': 1198, '比做': 1199, '盡頭': 1200, '一再': 1201, '收到': 1202, '理发店': 1203, '足夠': 1204, '亂': 1205, '未必': 1206, '上學': 1207, '在意': 1208, '運動': 1209, '或': 1210, '踢足球': 1211, '事上': 1212, '書店': 1213, '機': 1214, '适合': 1215, '盐': 1216, '夜晚': 1217, '腿': 1218, '此刻': 1219, '冠军': 1220, '三周': 1221, '刚': 1222, '忙': 1223, '烤肉': 1224, '经常': 1225, '不规则': 1226, '真實': 1227, '彈': 1228, '不錯': 1229, '跌': 1230, '这门': 1231, '零在': 1232, '經到': 1233, '決定': 1234, '没能念': 1235, '圖書館裡': 1236, '我當': 1237, '顧': 1238, '鬼魂': 1239, '染成': 1240, '未來會': 1241, '感动': 1242, '風箏節': 1243, '很难': 1244, '一段': 1245, '鑰匙': 1246, '美国': 1247, '這週': 1248, '生日': 1249, '他常': 1250, '我羨慕': 1251, '房间内': 1252, '倆': 1253, '真是': 1254, '嗎': 1255, '一整天': 1256, '濃了': 1257, '大象': 1258, '了許': 1259, 'Ogai': 1260, '试图': 1261, '才能': 1262, '舅母': 1263, '戒酒': 1264, '信守': 1265, '机会': 1266, '紐約': 1267, '送行': 1268, '数字': 1269, '越': 1270, '鋼琴課': 1271, '谢谢': 1272, '陰涼': 1273, '很困': 1274, '週前': 1275, '哭': 1276, '形式': 1277, '闪光灯': 1278, '总': 1279, '1989': 1280, '最近': 1281, '還多': 1282, '一般而言': 1283, '想要': 1284, '迷了路': 1285, '右': 1286, '冲走': 1287, '放': 1288, '這堂': 1289, '原因': 1290, '翻译': 1291, '辦事處': 1292, '每隔': 1293, '了': 1294, '三天': 1295, '服从命令': 1296, '出國': 1297, '老先生': 1298, '不良': 1299, '监狱': 1300, 'z': 1301, '鬍': 1302, '澳大利': 1303, '这些': 1304, '便': 1305, '之一': 1306, '指向': 1307, 'CD': 1308, '赢': 1309, '怎么办': 1310, '花園': 1311, '眼裡': 1312, '湯姆能': 1313, '当然': 1314, '多久': 1315, '杀': 1316, '留下': 1317, '感觉': 1318, '这么': 1319, '繼續': 1320, '淡水鱼': 1321, '是不是': 1322, '鎮上': 1323, '工业': 1324, '坐在': 1325, '作準備': 1326, '友情': 1327, '將會': 1328, '請問': 1329, '高呼': 1330, '我現': 1331, '人來': 1332, '一人': 1333, '尝试': 1334, '安慰': 1335, '一員': 1336, '必须': 1337, '跑步': 1338, '好': 1339, '怀': 1340, '說': 1341, '黑色': 1342, '靠': 1343, '形态': 1344, '冬夜': 1345, '500': 1346, '當然': 1347, '根源': 1348, '一會兒': 1349, '交通事故': 1350, '一塊': 1351, '当时': 1352, '都': 1353, '离开': 1354, '照射': 1355, '受了伤': 1356, '一點熱': 1357, '隨時': 1358, '我想': 1359, '沒時間': 1360, '正在': 1361, '表弟': 1362, '身份': 1363, '詞源': 1364, '没用': 1365, '粉末': 1366, '羽毛球拍': 1367, '岩石': 1368, '通常': 1369, '胞胎': 1370, '做些': 1371, '结束': 1372, '貓': 1373, '談過': 1374, '混合': 1375, '我們': 1376, '敲门': 1377, '小提琴': 1378, '設法': 1379, '灾难': 1380, '那里': 1381, '正忙': 1382, '旷课': 1383, '控制': 1384, '有罪': 1385, '大聲': 1386, '科学': 1387, '美感': 1388, '盡力': 1389, '上床': 1390, '幾歲': 1391, '一半': 1392, '車子': 1393, '及': 1394, '干嘛': 1395, '一口': 1396, '一支': 1397, '早上': 1398, '下去': 1399, '畜牲': 1400, '夏天': 1401, '小說': 1402, '点半': 1403, '發蓬': 1404, '將在': 1405, '走': 1406, '每晚': 1407, '任何人': 1408, '隔壁': 1409, '無論': 1410, '希尔顿酒店': 1411, '点火': 1412, '碰巧': 1413, '英里': 1414, '敢': 1415, '一次': 1416, '扔掉': 1417, '取決': 1418, '有趣': 1419, '巨大成功': 1420, '打': 1421, '早期': 1422, '大阪': 1423, '好久不见': 1424, '時間': 1425, '太遠': 1426, '街': 1427, '车库': 1428, '計劃': 1429, '協議': 1430, '誰': 1431, '記什麼': 1432, '更想': 1433, '折好': 1434, '草地': 1435, '打開': 1436, '不快': 1437, '不错': 1438, '商店': 1439, '公園裡': 1440, '抽出': 1441, '动物园': 1442, '兄弟': 1443, '不见': 1444, '我問': 1445, '胶水': 1446, '不该': 1447, '新': 1448, '一条': 1449, '学了': 1450, '靴子': 1451, '钱': 1452, '这种': 1453, '出差': 1454, '宾馆': 1455, '相似': 1456, '重大': 1457, '貴': 1458, '出': 1459, '您': 1460, '肩膀': 1461, '寫': 1462, '這個島': 1463, '昨天晚上': 1464, '妥協': 1465, '巧克力': 1466, '提供': 1467, '謊': 1468, '从来不': 1469, '火車': 1470, '導': 1471, '社团活动': 1472, '令人': 1473, '等于': 1474, '辆车': 1475, '公平': 1476, '那次': 1477, '否則': 1478, '假裝': 1479, '機鈴聲': 1480, '歌': 1481, '喉嚨': 1482, '兩袋': 1483, '平行': 1484, '否认': 1485, '好几个': 1486, '狗': 1487, '国际性': 1488, '看起来': 1489, '打招呼': 1490, '一窩': 1491, '談談': 1492, '适应': 1493, '医生': 1494, '愉快': 1495, '低': 1496, '湯姆不會': 1497, '鸟儿': 1498, '天上': 1499, '丈夫': 1500, '罐子': 1501, '\\n': 1502, '在羅馬過': 1503, '世界各地': 1504, '中國': 1505, '大利': 1506, '有風險': 1507, '擔心': 1508, '胡椒': 1509, '鹽': 1510, '想象': 1511, '美好': 1512, '我本': 1513, '組討論': 1514, '据': 1515, '负责人': 1516, '吃水果': 1517, '別': 1518, '他怕': 1519, '破碎': 1520, '出发': 1521, '場合': 1522, '親自去': 1523, '打算': 1524, '分享': 1525, '湯姆將': 1526, '另外': 1527, '哥哥': 1528, '經決': 1529, '寄信': 1530, '一些': 1531, '那个': 1532, '百萬': 1533, '和平': 1534, '識到': 1535, '看到': 1536, '大吃一惊': 1537, '封': 1538, '最终': 1539, '附近': 1540, '這個藥': 1541, '是種': 1542, '天使': 1543, '非去不可': 1544, '人要': 1545, '最差': 1546, '额外': 1547, '扔回': 1548, '黑': 1549, '湯姆欣賞': 1550, '晚飯': 1551, '赞成': 1552, '差不多': 1553, '建議': 1554, '坏消息': 1555, '前搖動': 1556, '搜查': 1557, '轨道': 1558, '總': 1559, '20': 1560, '地方': 1561, '那會': 1562, '停車': 1563, '传给': 1564, '早点': 1565, '发明': 1566, '纸条': 1567, '餅乾': 1568, '火災': 1569, '坚韧不拔': 1570, '最': 1571, '畢業': 1572, '有权': 1573, '劫': 1574, '測驗': 1575, '與眾': 1576, '湖上': 1577, '刚够': 1578, '张': 1579, '影院': 1580, '房间': 1581, '一聲': 1582, '白葡萄酒': 1583, '警察': 1584, '这条': 1585, '神秘': 1586, '渴望': 1587, '?': 1588, '女孩': 1589, '新来': 1590, '存在': 1591, '煩': 1592, '上課': 1593, '这个': 1594, '尋常': 1595, '入睡': 1596, '興奮': 1597, '水': 1598, '如昔': 1599, '长不大': 1600, '感謝': 1601, '週日花': 1602, '她給': 1603, '中': 1604, '趕到': 1605, '下跌': 1606, '走進': 1607, '羊毛衣': 1608, '離開': 1609, '情況': 1610, '窗戶': 1611, '一顆': 1612, '害羞': 1613, '這讓': 1614, '不想': 1615, '权利': 1616, '卫星': 1617, '書': 1618, '看见': 1619, '理论': 1620, '住口': 1621, '天': 1622, '之后': 1623, '痛': 1624, '已经': 1625, '大學': 1626, '語言': 1627, '拉': 1628, '都給': 1629, '確實': 1630, '信息': 1631, '富裕': 1632, '微笑': 1633, '走极端': 1634, '務': 1635, '懂事': 1636, '别': 1637, '火裡': 1638, '末': 1639, '留給': 1640, '再試': 1641, '街角': 1642, '简单': 1643, '游泳池': 1644, '来看': 1645, '儉用': 1646, '美國成': 1647, '這支': 1648, '笑话': 1649, '宣布': 1650, '牙齿': 1651, '一位': 1652, '都灑': 1653, '刮下': 1654, '开门': 1655, '湯姆上': 1656, '筆記本': 1657, '诺弗勒': 1658, '可以': 1659, '潑': 1660, '这次': 1661, '手提箱': 1662, '喝水': 1663, '像': 1664, '演唱': 1665, '改变': 1666, '迎': 1667, '口': 1668, '爸种': 1669, '“': 1670, '歲': 1671, '可': 1672, '新家': 1673, '西班牙': 1674, '院子': 1675, '学会': 1676, '汤姆': 1677, '趕': 1678, '之後便': 1679, '上方': 1680, '想到': 1681, '你將': 1682, '鬼点子': 1683, '用來': 1684, '旧书': 1685, '许多': 1686, '實話': 1687, '受傷': 1688, '熟': 1689, '初愈': 1690, '检查': 1691, '評價': 1692, '啊': 1693, '義': 1694, '這張票': 1695, '通過': 1696, '車': 1697, '不起': 1698, '埋怨': 1699, '你們': 1700, '记者': 1701, '那件': 1702, '眼盲': 1703, '除了': 1704, '联系': 1705, '争议': 1706, '失踪': 1707, '作業': 1708, '长信': 1709, '關於': 1710, '硫磺': 1711, '九点': 1712, '一门': 1713, '上边': 1714, '家庭': 1715, '耳朵': 1716, '每': 1717, '緊張': 1718, '离婚': 1719, '女性': 1720, '一盏灯': 1721, '秘密': 1722, '廳': 1723, '形容词': 1724, '耐心': 1725, '几天': 1726, '壮观': 1727, '门口': 1728, '相處': 1729, '這房間': 1730, '我見': 1731, '纽约': 1732, '獨自': 1733, '子': 1734, '走路': 1735, '議程': 1736, '这会': 1737, '四年': 1738, '成員': 1739, '往往': 1740, '意見': 1741, '古典音乐': 1742, '人工智能': 1743, '並不總是': 1744, '少': 1745, '信心': 1746, '動物': 1747, '社交': 1748, '年': 1749, '開會': 1750, '无用论': 1751, '越军': 1752, '我想試': 1753, '辦法': 1754, '仔细': 1755, '更好': 1756, '入場': 1757, '社的': 1758, '開燈': 1759, '物理': 1760, '解開': 1761, '公園': 1762, '我': 1763, '遞給': 1764, '颜色': 1765, '作家': 1766, '襯衫': 1767, '担心': 1768, '有益健康': 1769, '黑暗': 1770, '祝您': 1771, '整齊': 1772, '专家': 1773, '这件': 1774, '我会': 1775, '确保': 1776, '高': 1777, '要求': 1778, '鋼筆': 1779, '校长': 1780, '想像': 1781, '”': 1782, '車給': 1783, '學生': 1784, '学法语': 1785, '清晨': 1786, '不是': 1787, '手臂': 1788, '逆向行驶': 1789, '确切': 1790, '修好': 1791, '好得多': 1792, '難': 1793, '當作': 1794, '學法語': 1795, '问题': 1796, '支付': 1797, '只': 1798, '私下': 1799, '闖入': 1800, '經贏': 1801, '引擎': 1802, '錢': 1803, '哪一條': 1804, '價值': 1805, '生存': 1806, '含有': 1807, '语言': 1808, '創立': 1809, '得': 1810, '长相': 1811, '两个': 1812, '報警': 1813, '下午': 1814, '回去': 1815, '鋼琴': 1816, '我學習': 1817, '今晚': 1818, '決心': 1819, '考試': 1820, '感到': 1821, '打破': 1822, '擦拭': 1823, '當心': 1824, '處': 1825, '幫瑪麗': 1826, '国际': 1827, '干涉': 1828, '与否': 1829, '上帝': 1830, '经验': 1831, '彩票': 1832, '一架': 1833, '包': 1834, '潜逃': 1835, '增长': 1836, '不幸': 1837, '連': 1838, '飛': 1839, '儿': 1840, '知识': 1841, '胆小鬼': 1842, '手机': 1843, '一家': 1844, '妻子': 1845, '时候': 1846, '它': 1847, '發生': 1848, '旁': 1849, '认为': 1850, '校庆': 1851, '打开': 1852, '比薩': 1853, '一朵': 1854, '聽音樂': 1855, '你们': 1856, '任教': 1857, '停止': 1858, '照顾': 1859, '會醒': 1860, '顏色': 1861, '7': 1862, '多余': 1863, '动': 1864, '没人': 1865, '帮': 1866, '星期天': 1867, '山丘': 1868, '碟': 1869, '放在': 1870, '社會': 1871, '鼻子': 1872, '又': 1873, '看': 1874, '瑪麗': 1875, '首都': 1876, '河': 1877, '山坡': 1878, '以前': 1879, '窗关': 1880, '倫敦': 1881, '食物': 1882, '睡覺': 1883, '問了': 1884, '未婚': 1885, '而且': 1886, '園藝': 1887, '開心': 1888, '啞': 1889, '想': 1890, '蔬菜': 1891, '結婚': 1892, '休假': 1893, '房屋': 1894, '战争': 1895, '不成': 1896, '皆': 1897, '亭': 1898, '同样': 1899, '我的雙': 1900, '能夠': 1901, '那幢': 1902, '骑车': 1903, '很多': 1904, '幾個': 1905, '地球': 1906, '包里': 1907, '我们': 1908, '内': 1909, '本书': 1910, '长久': 1911, '备受': 1912, '合開': 1913, '绅士': 1914, '冰淇淋': 1915, '它们': 1916, '有点像': 1917, '不常見': 1918, '當成': 1919, '当': 1920, '点儿': 1921, '飲': 1922, '本意': 1923, '國中生': 1924, '兴奋': 1925, '喝點': 1926, '就读': 1927, '背景': 1928, '我能': 1929, '四匹': 1930, '几个': 1931, '檢查': 1932, '不吸': 1933, '理': 1934, '很久以前': 1935, '再次': 1936, '首歌': 1937, '困惑': 1938, '添些': 1939, '往常': 1940, '准备': 1941, '車程': 1942, '渡假': 1943, '稍微': 1944, '叫作': 1945, '真': 1946, '信用卡': 1947, '就要': 1948, '那种': 1949, '事故': 1950, '久留': 1951, '電話': 1952, '這把傘': 1953, '現在': 1954, '告訴過': 1955, '想法': 1956, '弟弟': 1957, '自身': 1958, '況下': 1959, '事实上': 1960, '貨車': 1961, '公路': 1962, '稍': 1963, '去过': 1964, '疲力': 1965, '镜子': 1966, '告訴': 1967, '泰來': 1968, '还清': 1969, '巴黎': 1970, '因病': 1971, '蠢': 1972, '阵雨': 1973, '环境污染': 1974, '喜歡': 1975, '错': 1976, '那儿': 1977, '著牆': 1978, '湯姆造': 1979, '記憶力': 1980, '公司': 1981, '日記': 1982, '鬆': 1983, '點': 1984, '地鐵站': 1985, '浇水': 1986, '大致': 1987, '故事': 1988, '一百多个': 1989, '解决问题': 1990, '洋芋片': 1991, '闻到': 1992, '温和': 1993, '與': 1994, '年轻人': 1995, '視力': 1996, '還給': 1997, '用尽': 1998, '不理': 1999, '盯': 2000, '不關': 2001, '實用': 2002, '令': 2003, '虽然': 2004, '怕死': 2005, '法國': 2006, '一百年': 2007, '火焰': 2008, '一點': 2009, '一名': 2010, '映像': 2011, '弹钢琴': 2012, '换衣服': 2013, '會過': 2014, '惹事': 2015, '進行': 2016, '有钱': 2017, '不去': 2018, '漫畫': 2019, '並': 2020, '讓': 2021, '公里': 2022, '母語': 2023, '反对': 2024, '九點鐘': 2025, '濱松': 2026, '但願': 2027, '不够': 2028, '毒品': 2029, '讀書': 2030, '當你年': 2031, '小心': 2032, '不要': 2033, '什麼問': 2034, '家小': 2035, '帶路': 2036, '三': 2037, '獨立': 2038, '拿到': 2039, '相關': 2040, '夏威夷': 2041, '我將': 2042, '欠': 2043, '八小時': 2044, '頓過': 2045, '獨': 2046, '湯姆己': 2047, '百分之百': 2048, '雨下': 2049, '文件': 2050, '3': 2051, '所': 2052, '溜冰': 2053, '这栋': 2054, '祖父': 2055, '外语': 2056, '這張': 2057, '哭泣': 2058, '法语': 2059, '指使': 2060, '冲': 2061, '进': 2062, '反': 2063, '拿': 2064, '關燈': 2065, '課': 2066, '功課': 2067, '教育': 2068, '招呼': 2069, '暴风雨': 2070, '會來': 2071, '直到': 2072, '猫': 2073, '获得': 2074, '从': 2075, '十分': 2076, '洋蔥': 2077, '後': 2078, '今天上午': 2079, '看出': 2080, '許多義': 2081, '根本': 2082, '我錯': 2083, '讲': 2084, '座位': 2085, '挂': 2086, '經過': 2087, '怎麼樣': 2088, '憤怒': 2089, '粉': 2090, '早就': 2091, '与': 2092, '電子': 2093, '打网球': 2094, '搅': 2095, '有关': 2096, '媽媽': 2097, '更糟': 2098, '遵循': 2099, '凱莉': 2100, '之前': 2101, '人口': 2102, '哪顶': 2103, '累': 2104, '上班族': 2105, '承認': 2106, '很': 2107, '箱根': 2108, '獻給': 2109, '中學': 2110, '親他': 2111, '不好意思': 2112, '受罰': 2113, '十一': 2114, '報載': 2115, '著為': 2116, '請': 2117, '看過': 2118, '醒醒': 2119, '太快': 2120, '为': 2121, '两座': 2122, '以英語': 2123, '哪顆': 2124, '这里': 2125, '改善': 2126, '周日': 2127, '厨房': 2128, '扯掉': 2129, '接着': 2130, '铁路': 2131, '被遗弃': 2132, '很慢': 2133, '除掉': 2134, '辣': 2135, '中午': 2136, '濕': 2137, '當我': 2138, '出门儿': 2139, '前天': 2140, '低估': 2141, '兩天': 2142, '牛排': 2143, '接受': 2144, '做飯': 2145, '灵魂': 2146, '男': 2147, '死亡': 2148, '亞': 2149, '抱怨': 2150, '聽': 2151, '給了': 2152, '仅仅': 2153, '桌上': 2154, '放松': 2155, '关灯': 2156, '裁判': 2157, '無禮': 2158, '依然': 2159, '照片': 2160, '跟': 2161, '五十': 2162, '限': 2163, '叫': 2164, '上次': 2165, '抹': 2166, '以后': 2167, '監獄': 2168, '听说': 2169, '神無處': 2170, '一致': 2171, '召开': 2172, '捷克语': 2173, '湯姆真': 2174, '公車': 2175, '節': 2176, '致死': 2177, '进步': 2178, '快该': 2179, '猴': 2180, '从没': 2181, '我回': 2182, '护士': 2183, '心地': 2184, '藉口': 2185, '老朋友': 2186, '這計畫': 2187, '一般': 2188, '發車': 2189, '解决': 2190, '湯姆幫': 2191, '火车': 2192, '一部分': 2193, '機會習': 2194, '蛋糕': 2195, '静谧': 2196, '參加戲': 2197, '五小时': 2198, '担忧': 2199, '周末': 2200, '從': 2201, '前有': 2202, '支票': 2203, '帮助': 2204, ',': 2205, '!': 2206, '巴士': 2207, '成人': 2208, '那天': 2209, '但是': 2210, '年纪': 2211, '登記': 2212, '服務': 2213, '屋里': 2214, '老人': 2215, '极好': 2216, '明白': 2217, '郵件': 2218, '散散步': 2219, '以至于': 2220, '生活': 2221, '會': 2222, '成為': 2223, '一节': 2224, '再': 2225, '影响': 2226, '鉤子': 2227, '修理': 2228, '很明顯': 2229, '上漲': 2230, '騙子': 2231, '列车': 2232, '命': 2233, '醫生': 2234, '面帶': 2235, '馬車': 2236, '這本書': 2237, '总是': 2238, '成績': 2239, '興趣': 2240, '天氣': 2241, '太阳': 2242, '綠色': 2243, '佈': 2244, '使用': 2245, '她現': 2246, '一切': 2247, '宝宝': 2248, '战乱': 2249, '有空': 2250, '快': 2251, '感': 2252, '身体': 2253, '订': 2254, '著餐': 2255, '兒子': 2256, '几点': 2257, '泰晤士河': 2258, '偶然间': 2259, '问': 2260, '不再': 2261, '柳橙': 2262, '烦心': 2263, '將頭': 2264, '半': 2265, '每首歌': 2266, '目標': 2267, '造': 2268, '帮忙': 2269, '工作': 2270, '飲食': 2271, '行动': 2272, '待': 2273, '午餐': 2274, '戰爭': 2275, '「': 2276, '营销部': 2277, '行为': 2278, '风险': 2279, '什麼': 2280, '毫無根據': 2281, '实际上': 2282, '成綠色': 2283, '當': 2284, '过多': 2285, '称为': 2286, '鼓励': 2287, '麻煩': 2288, '变得': 2289, '滑冰': 2290, '泡': 2291, '嚇到': 2292, '垒球': 2293, '老虎': 2294, '掛在': 2295, '暴風雨': 2296, '职位': 2297, '从来': 2298, '地離開': 2299, '分鐘': 2300, '裡有': 2301, '分钟': 2302, '影響': 2303, '機場': 2304, '造成': 2305, '筑巢': 2306, '認成別': 2307, '收集': 2308, '大衣': 2309, '叔叔': 2310, '回來': 2311, '一生': 2312, '印度': 2313, 'AI': 2314, '這名': 2315, '咖哩': 2316, '姐姐': 2317, '大学': 2318, '低于': 2319, '被': 2320, '家務': 2321, '雪': 2322, '风': 2323, '1988': 2324, '這件': 2325, '中国': 2326, '照相机': 2327, '男人': 2328, '走開': 2329, '還沒有': 2330, '送': 2331, '銀行': 2332, '烟熏': 2333, '帽子': 2334, '本好': 2335, '那些': 2336, '看着': 2337, '睡觉': 2338, '只是': 2339, '很涼爽': 2340, '會嚇': 2341, '幫助': 2342, '東西': 2343, '個班裡': 2344, '不該': 2345, '賜予': 2346, '我覺': 2347, '五分': 2348, '入场费': 2349, '礼貌': 2350, '真糟糕': 2351, '設定': 2352, '停': 2353, '花园里': 2354, '不會': 2355, '来信': 2356, '提出': 2357, '会': 2358, '军队': 2359, '外行': 2360, '点着': 2361, '真是太': 2362, '傑克': 2363, '船': 2364, '向日葵': 2365, '民主': 2366, '你': 2367, '瓶子': 2368, '三十年': 2369, '车': 2370, '离': 2371, '旅游': 2372, '运动': 2373, '摘下': 2374, '抓住': 2375, '不明': 2376, '散步': 2377, '這台': 2378, '你現': 2379, '男朋友': 2380, '男孩': 2381, '新房子': 2382, '眼泪': 2383, '这样的话': 2384, '谢': 2385, '不遠': 2386, '教': 2387, '听': 2388, '電話給': 2389, '它花': 2390, '搆': 2391, '來': 2392, '下雪': 2393, '比薩餅': 2394, '不會來': 2395, '哭哭啼啼': 2396, '久': 2397, '旁邊': 2398, '木頭': 2399, '坐车去': 2400, '講英語': 2401, '寒假': 2402, '達': 2403, '等': 2404, '取消': 2405, '头': 2406, '来到': 2407, '愚蠢': 2408, '一下': 2409, '週末': 2410, '旅': 2411, '读懂': 2412, '，': 2413, '打败': 2414, '臨': 2415, '幚': 2416, '很久': 2417, '自': 2418, '馬': 2419, '刮': 2420, '外國': 2421, '維也納': 2422, '存錢': 2423, '生气': 2424, '爱': 2425, '打击': 2426, '开学': 2427, '權力': 2428, '交友': 2429, '愛瘋': 2430, '偷': 2431, '酒鬼': 2432, '醉': 2433, '不如': 2434, '杯子': 2435, '窗': 2436, '太难': 2437, '這部': 2438, '狐狸': 2439, '好日子': 2440, '握手': 2441, '的車': 2442, '这画': 2443, '早來': 2444, '永远': 2445, '曾开': 2446, '材料': 2447, '真傻': 2448, '他畫': 2449, '屋子': 2450, '滑倒': 2451, '翻': 2452, '尸体': 2453, '该': 2454, '旅行': 2455, '離': 2456, '嚴格': 2457, '授獎': 2458, '行李': 2459, '嫁給': 2460, '努力学习': 2461, '凡事': 2462, '花有': 2463, '城市': 2464, '她家': 2465, '忍住': 2466, '蜂': 2467, '並非': 2468, '秘书': 2469, '答案': 2470, '驚訝': 2471, '那样': 2472, '现在': 2473, '要': 2474, '他们': 2475, '理解': 2476, '迷路': 2477, '承诺': 2478, '足球': 2479, '網球': 2480, '薪水': 2481, '那樣': 2482, '听腻': 2483, '将要': 2484, '桶子': 2485, '水果': 2486, '早點': 2487, '觉得': 2488, '我寄給': 2489, '掉': 2490, '沒上學': 2491, '冷水': 2492, '一项': 2493, '预言': 2494, '吗': 2495, '風箏給': 2496, '受欢迎': 2497, '盒子': 2498, '没少': 2499, '发表': 2500, '試著': 2501, '下': 2502, '我的車': 2503, '撿': 2504, '决定': 2505, '\"': 2506, '点': 2507, '房里': 2508, '鬥爭': 2509, '省': 2510, '我給': 2511, '毅力': 2512, '》': 2513, '特別': 2514, 'IBM': 2515, '剪成': 2516, '哪裡': 2517, '书': 2518, '快要': 2519, '湯姆是': 2520, '攝影社': 2521, '回应': 2522, '可是': 2523, '勸': 2524, '玩': 2525, '有意思': 2526, '悲劇': 2527, '来讲': 2528, '千米': 2529, '親現': 2530, '週日': 2531, '中會': 2532, '床': 2533, '数码相机': 2534, '想查': 2535, '音樂': 2536, '就是': 2537, '玩四輪': 2538, '身體': 2539, '生命': 2540, '所知': 2541, '友誼': 2542, '依賴': 2543, '吸煙': 2544, '的': 2545, '讀過': 2546, '下山': 2547, '光榮': 2548, '報告': 2549, '一边': 2550, '侵犯': 2551, '半个': 2552, '錯': 2553, '见过': 2554, '一間': 2555, '器樂': 2556, '跳舞': 2557, '雞': 2558, '節目': 2559, '看上去': 2560, '晚': 2561, '隊員': 2562, '茶匙': 2563, '苹果': 2564, '經歷': 2565, '樂團裡': 2566, '礼物': 2567, '嗯': 2568, '有個': 2569, '道歉': 2570, '癌症': 2571, '愛我們': 2572, '他給': 2573, '不久': 2574, '來些': 2575, '開車': 2576, '几次': 2577, '尽': 2578, '消防': 2579, '這一點': 2580, '女兒': 2581, '我遇': 2582, '評分': 2583, '裡嗎': 2584, '星期': 2585, '受歡': 2586, '會遲': 2587, '大量': 2588, '他人': 2589, '西施': 2590, '這所大學': 2591, '穿': 2592, '完成': 2593, '冬天': 2594, '家人': 2595, '吃': 2596, '冻僵': 2597, '一块': 2598, '蛋': 2599, '比起': 2600, '個': 2601, '上课': 2602, '整場': 2603, '温度计': 2604, '做': 2605, '那麼': 2606, '保安': 2607, '溫度': 2608, '洗手': 2609, '有风': 2610, '一頭': 2611, '尊敬': 2612, '隐私': 2613, '教師': 2614, '六點鐘': 2615, '目标': 2616, '可能': 2617, '季節': 2618, '語就': 2619, '根據': 2620, '圖片': 2621, '不会': 2622, '誤解': 2623, '聖誕節': 2624, '下厚霜': 2625, '跳': 2626, '爸会': 2627, '怪人': 2628, '9': 2629, '渴': 2630, '安排': 2631, '借給': 2632, '点到': 2633, '成功': 2634, '无辜': 2635, '胜任': 2636, '我媽媽': 2637, '我會': 2638, '负责': 2639, '事': 2640, '因为': 2641, '焰火': 2642, '满意': 2643, '难不成': 2644, '正確': 2645, '尤其': 2646, '緊': 2647, '升起': 2648, '2': 2649, '露營': 2650, '公開場': 2651, '公立': 2652, '鉛筆': 2653, '母亲': 2654, '干什么': 2655, '好处': 2656, '铅笔': 2657, '了輛': 2658, '迟到': 2659, '當這場': 2660, '好鞋': 2661, '呼吸': 2662, '上海': 2663, '幾乎': 2664, '小孩': 2665, '新車': 2666, '出現': 2667, '一把': 2668, '坐': 2669, '教授': 2670, '組裝': 2671, '玩具': 2672, '睁开': 2673, '問問': 2674, '孫子': 2675, '奶油': 2676, '桥': 2677, '出版': 2678, '感興趣': 2679, '讲座': 2680, '经济': 2681, '數學': 2682, '相信': 2683, '惹': 2684, '倒': 2685, '一樓': 2686, '不爱': 2687, '喷剂': 2688, '买辆': 2689, '椅上': 2690, '池塘': 2691, '俱乐部': 2692, '退役军人': 2693, '知道': 2694, '优雅': 2695, '有名': 2696, '那匹马': 2697, '小時': 2698, '起床': 2699, '晚饭': 2700, '懲罰過': 2701, '葬禮': 2702, '罪魁祸首': 2703, '爆炸': 2704, '北半球': 2705, '鱼': 2706, '他會': 2707, '師': 2708, '路': 2709, '上加些': 2710, '洗乾淨': 2711, '味': 2712, '后': 2713, '一百岁': 2714, '小说': 2715, '来杯': 2716, '100': 2717, '减轻': 2718, '湯姆要': 2719, '并': 2720, '暖和': 2721, '简便': 2722, '羞怯': 2723, '期望': 2724, '再見': 2725, '他終': 2726, '正': 2727, '簡單': 2728, '妈妈': 2729, '歌手': 2730, '生病': 2731, '屋顶': 2732, '自助式': 2733, '時候': 2734, '（': 2735, '安靜': 2736, '高兴': 2737, '一個專': 2738, '四季': 2739, '角度': 2740, '裡': 2741, '滿': 2742, '滑雪': 2743, '愛': 2744, '豫則立': 2745, '親家': 2746, '有三個': 2747, '誕禮物': 2748, '電': 2749, '歡紅': 2750, '匯率': 2751, '樂': 2752, '加拿大': 2753, '開槍': 2754, '桌子': 2755, '够': 2756, '意见': 2757, '相邻': 2758, '僵': 2759, '巧手': 2760, '否極': 2761, '一封信': 2762, '之间': 2763, '建议': 2764, '項目': 2765, '時鐘': 2766, '凍': 2767, '雇佣': 2768, '放映': 2769, '一天': 2770, '那事': 2771, '惊讶': 2772, '情绪': 2773, '很深': 2774, '参加': 2775, '什么样': 2776, '很漂亮': 2777, '能活': 2778, '恐怖片': 2779, '你給': 2780, '翻譯': 2781, '跑得快': 2782, '时间': 2783, '纸币': 2784, '起來': 2785, '鐘': 2786, '我喜': 2787, '开车': 2788, '隻': 2789, '和玛丽': 2790, '文章': 2791, '數學得': 2792, '擔任': 2793, '著': 2794, '心': 2795, '學': 2796, '银行': 2797, '不用': 2798, '搞': 2799, '回来': 2800, '中肯': 2801, '湯姆高興': 2802, '多酒': 2803, '湯姆笑': 2804, '这支': 2805, '甚麼': 2806, '至': 2807, '这项': 2808, '許多人': 2809, '雨': 2810, '勉強': 2811, '汽車': 2812, '遊戲': 2813, '喝咖啡': 2814, '东京': 2815, '老板': 2816, '部': 2817, '以上': 2818, '聽到': 2819, '求助': 2820, '新车': 2821, '突然': 2822, '黑海': 2823, '他會來': 2824, '非常': 2825, '還年': 2826, '为止': 2827, '环游世界': 2828, '玻璃杯': 2829, '早起': 2830, '名婦': 2831, '晴转': 2832, '争吵': 2833, '傾向': 2834, '左右': 2835, '输': 2836, '好点': 2837, '和': 2838, '急': 2839, '今天': 2840, '家具': 2841, '节食': 2842, '早餐': 2843, '五年': 2844, '呢': 2845, '這裡': 2846, '地震': 2847, '牙痛': 2848, '房間裡': 2849, '準備': 2850, '過美國': 2851, '比': 2852, '這事': 2853, '里': 2854, '聽起': 2855, '哪': 2856, '喝': 2857, '好多': 2858, '畫鳥': 2859, '演奏': 2860, '忘记': 2861, '他劃': 2862, '枪杀': 2863, '桌邊': 2864, '禮物': 2865, '電視': 2866, '樂瘋': 2867, '清潔': 2868, '奢侈品': 2869, '绝大多数': 2870, '列': 2871, '圖書館': 2872, '剩': 2873, '买': 2874, '擅長': 2875, '逮捕': 2876, '讀點': 2877, '热点': 2878, '木工': 2879, '茶': 2880, '车站': 2881, '关门': 2882, '像是': 2883, '肉': 2884, '危險': 2885, '演員': 2886, '眼鏡': 2887, '女儿': 2888, '登山': 2889, '仅': 2890, '夏季': 2891, '玫瑰花': 2892, '钥匙': 2893, '並沒有': 2894, '總經理': 2895, '我為': 2896, '荷兰': 2897, '拍山': 2898, '我寧願': 2899, '嗨': 2900, '傷害': 2901, '隨身': 2902, '打扑克': 2903, '那本书': 2904, '肯定': 2905, '丢': 2906, '留': 2907, '特惠': 2908, '樹不會長': 2909, '让': 2910, '全是': 2911, '以及': 2912, '嘿': 2913, '后门': 2914, '湯姆問': 2915, '職業': 2916, '汽车': 2917, '比水': 2918, '兒書': 2919, '做完作业': 2920, '持续': 2921, '请教': 2922, '聲明': 2923, '意思': 2924, '開除': 2925, '風景': 2926, '能': 2927, '藍色': 2928, '没有': 2929, '手帕': 2930, '聽眾': 2931, '軟': 2932, '难': 2933, '路车': 2934, '練習彈': 2935, '有件事': 2936, '好像': 2937, '折': 2938, '這夥人': 2939, '眼睛': 2940, '怪響': 2941, '餐廳': 2942, '依旧': 2943, '香蕉': 2944, '很長': 2945, '下个月': 2946, '哪本': 2947, '著名': 2948, '双胞胎': 2949, '威尼斯': 2950, '开到': 2951, '輕人': 2952, '8': 2953, '見': 2954, '寢': 2955, '一点': 2956, '車撞': 2957, '懂德語': 2958, '十年': 2959, '天氣將': 2960, '着想': 2961, '位': 2962, '戴': 2963, '花': 2964, '申請': 2965, '说得通': 2966, '教英語': 2967, '消息': 2968, '難題': 2969, '指责': 2970, '不能': 2971, '還要': 2972, '家里': 2973, '一': 2974, '紙用': 2975, '容易': 2976, '尽快': 2977, '情人': 2978, '勝過': 2979, '接': 2980, '好多钱': 2981, '版': 2982, '早': 2983, '以來': 2984, '很醜': 2985, '護照': 2986, '外套': 2987, '包裹': 2988, '5': 2989, '金色': 2990, '勝於': 2991, '缺乏': 2992, '審': 2993, '彈鋼琴': 2994, '愿意': 2995, '告诉': 2996, '空房': 2997, '德語': 2998, '震惊': 2999, '洗牌': 3000, '好吃': 3001, '噪音': 3002, '但': 3003, '較': 3004, '當雨': 3005, '有': 3006, '忘': 3007, '艰难': 3008, '家裡': 3009, '用戶': 3010, '那個': 3011, '好几': 3012, '嚮': 3013, '补给': 3014, '很受': 3015, '小狗': 3016, '身体健康': 3017, '会下': 3018, '做不了': 3019, '侍二主': 3020, '坏': 3021, '很傷': 3022, '上班': 3023, '竟然': 3024, '母語者': 3025, '獅子': 3026, '法律': 3027, '应当': 3028, '复苏': 3029, '公园': 3030, '失望': 3031, '455': 3032, '如何': 3033, '他': 3034, '港口城市': 3035, '我用': 3036, '革命': 3037, '應': 3038, '東京站': 3039, '改不了': 3040, '家伙': 3041, '裂开': 3042, '手腕': 3043, '名字': 3044, '工廠': 3045, '耳聾': 3046, '帶著': 3047, '号': 3048, '大富翁': 3049, '隱約': 3050, '其中': 3051, '站': 3052, '下週': 3053, '整天': 3054, '彎曲': 3055, '人事': 3056, '马路': 3057, '財富': 3058, '如果': 3059, '探訪': 3060, '車站': 3061, '短袖': 3062, '是': 3063, '爆米花': 3064, '碰': 3065, '过来': 3066, '他問': 3067, '之': 3068, '甚至': 3069, '欢迎': 3070, '新低': 3071, '几间': 3072, '開始': 3073, '立': 3074, '警察局': 3075, '怎麼換': 3076, '努力': 3077, '撞倒': 3078, '去年': 3079, '英语': 3080, '人們': 3081, '无用': 3082, '作': 3083, '邀请': 3084, '沒': 3085, '過量': 3086, '槍': 3087, '住': 3088, '晒黑': 3089, '內疚': 3090, '上': 3091, '见': 3092, '然后': 3093, '消费': 3094, '嬰兒': 3095, '很安靜': 3096, '考虑一下': 3097, '擠滿': 3098, '經長': 3099, '听到': 3100, '笑': 3101, '首歌曲': 3102, '人去': 3103, '歡辣': 3104, ' ': 3105, '慢': 3106, '法文': 3107, '廣告': 3108, '拷貝': 3109, '自助餐': 3110, '一直': 3111, '死': 3112, '午饭': 3113, '謠言': 3114, '没想到': 3115, '那': 3116, '感谢': 3117, '兒童': 3118, '爷爷': 3119, '一個': 3120, '试着': 3121, '比較': 3122, '拖延': 3123, '那時': 3124, '解決': 3125, '值得': 3126, '每件事': 3127, '氣味': 3128, '贷款': 3129, '拜訪': 3130, '镜': 3131, '很棒': 3132, '即使': 3133, '地舒適': 3134, '英語': 3135, '怎麼': 3136, '溫室': 3137, '派': 3138, '下雨': 3139, '同班': 3140, '这儿': 3141, '時': 3142, '生于': 3143, '發脾氣': 3144, 'Tom': 3145, '付钱': 3146, '木柴': 3147, '吃太多': 3148, '重要': 3149, '杂志': 3150, '筆跡': 3151, '扇門': 3152, '吉他': 3153, '人生': 3154, '演出': 3155, '兩種': 3156, '厕所': 3157, '的话': 3158, '这家': 3159, '含义': 3160, '醒': 3161, '聊胜于无': 3162, '請關': 3163, '地筋': 3164, '將照': 3165, '缺少': 3166, '一部': 3167, '得到': 3168, '三年': 3169, '遵守规则': 3170, '字': 3171, '自己': 3172, '喝啤酒': 3173, '上火': 3174, '輕': 3175, '在': 3176, '英国': 3177, '抓': 3178, '嗜好': 3179, '亲': 3180, '韩国': 3181, '废墟': 3182, '出發': 3183, '這輛': 3184, '看書': 3185, '學校': 3186, '继续': 3187, '一只': 3188, '浓妆': 3189, '活': 3190, '辦': 3191, '懷孕': 3192, '這棟': 3193, '罵': 3194, '動物園': 3195, '太烈': 3196, '明天': 3197, '她': 3198, '那裡': 3199, '接手': 3200, '裝滿水': 3201, '寄给': 3202, '面對': 3203, '通过': 3204, '踩': 3205, '必要': 3206, '给': 3207, '國家': 3208, '玩得': 3209, '政治': 3210}\n"
     ]
    }
   ],
   "source": [
    "input_token_index = dict(\n",
    "    [(token, i) for i, token in enumerate(input_tokens)])\n",
    "target_token_index = dict(\n",
    "    [(token, i) for i, token in enumerate(target_tokens)])\n",
    "\n",
    "print(\"\\ninput index:\")\n",
    "print(input_token_index)\n",
    "\n",
    "print(\"\\ntarget index:\")\n",
    "print(target_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17437cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape is (batch_size, time_steps, input_dim)\n",
      "so it will be (number of x, length of each x, dimension of x)\n",
      "\n",
      "encoder input shape:\n",
      "(2000, 32)\n",
      "\n",
      "decoder input shape:\n",
      "(2000, 32)\n",
      "\n",
      "decoder target shape:\n",
      "(2000, 32, 3211)\n",
      "\n",
      "encoder input data (1-hot):\n",
      "[[1842.  363. 1951. 1025.  821.  719.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [1988. 1410.  766.  677.  772. 1380.  668.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]]\n",
      "\n",
      "decoder input data (1-hot):\n",
      "[[ 734. 2779. 2341.    0. 2665.   30. 1502.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [ 734. 3034. 1917. 3034. 2545.  105.   30. 1502.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]]\n",
      "\n",
      "decoder target data (1-hot):\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, token in enumerate(input_text):\n",
    "        encoder_input_data[i, t] = input_token_index[token]\n",
    "    for t, token in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = target_token_index[token]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[token]] = 1.\n",
    "\n",
    "print(\"The shape is (batch_size, time_steps, input_dim)\")\n",
    "print(\"so it will be (number of x, length of each x, dimension of x)\")\n",
    "print(\"\\nencoder input shape:\")\n",
    "print(encoder_input_data.shape)\n",
    "print(\"\\ndecoder input shape:\")\n",
    "print(decoder_input_data.shape)\n",
    "print(\"\\ndecoder target shape:\")\n",
    "print(decoder_target_data.shape)\n",
    "            \n",
    "print(\"\\nencoder input data (1-hot):\")\n",
    "print(encoder_input_data[-2:])\n",
    "print(\"\\ndecoder input data (1-hot):\")\n",
    "print(decoder_input_data[-2:])\n",
    "print(\"\\ndecoder target data (1-hot):\")\n",
    "print(decoder_target_data[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a1b2d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (None, None)\n",
      "encoder_inputs: (None, None)\n",
      "state: (None, 128)\n",
      "encoder_outputs: (None, None, 128)\n"
     ]
    }
   ],
   "source": [
    "class Encoder(Model):\n",
    "    def __init__(self, vocab_size, latent_dim, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lstm = GRU(self.latent_dim,\n",
    "                        return_sequences=True,\n",
    "                        return_state=True,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        dropout=0.2,\n",
    "                        recurrent_dropout=0.2)\n",
    "        self.embedding = Embedding(vocab_size, latent_dim, mask_zero=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        print(f\"x: {x.shape}\")\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.lstm(x)\n",
    "        return output, state, x._keras_mask\n",
    "\n",
    "\n",
    "encoder_inputs = Input(shape=(None, ))\n",
    "encoder = Encoder(num_encoder_tokens, latent_dim, batch_size)\n",
    "encoder_outputs, state, encoder_embedding_mask = encoder(encoder_inputs)\n",
    "\n",
    "print(f\"encoder_inputs: {encoder_inputs.shape}\")\n",
    "print(f\"state: {state.shape}\")\n",
    "print(f\"encoder_outputs: {encoder_outputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3933572b",
   "metadata": {},
   "source": [
    "# If we don't use `W1` and `W2`, we will get a better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4f9c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class BahdanauAttention2(Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W1 = Dense(units, activation='sigmoid')\n",
    "        self.W2 = Dense(units, activation='sigmoid')\n",
    "        self.attention = tf.keras.layers.AdditiveAttention(dropout=0.2)\n",
    "        \n",
    "    def call(self, query, value, mask, encoder_mask):\n",
    "        print(f\"mask: {mask.shape}\")\n",
    "        print(f\"encoder_mask: {encoder_mask.shape}\")\n",
    "        # From Eqn. (4), `W1@ht`.\n",
    "        # w1_query = self.W1(query)\n",
    "        # w1_query = Dropout(0.2)(w1_query)\n",
    "\n",
    "        # From Eqn. (4), `W2@hs`.\n",
    "        # from memory to key\n",
    "        # w2_key = self.W2(value)\n",
    "        # w2_key = Dropout(0.2)(w2_key)\n",
    "        \n",
    "        context_vector, attention_weights = self.attention(\n",
    "            inputs = [query, value],\n",
    "            mask=[mask, encoder_mask],\n",
    "            return_attention_scores = True,\n",
    "        )\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b719832",
   "metadata": {},
   "source": [
    "# We can also try not to use hidden in Decoder (i.e., remove `initial_state=hidden`), all information comes from attention layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc194d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (None, None)\n",
      "hidden: (None, 128)\n",
      "enc_output: (None, None, 128)\n",
      "rnn_output: (None, None, 128)\n",
      "mask: (None, None)\n",
      "encoder_mask: (None, None)\n",
      "decoder_inputs: (None, None)\n",
      "state: (None, 128)\n",
      "decoder_outputs: (None, None, 3211)\n"
     ]
    }
   ],
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(self, vocab_size, latent_dim, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lstm = GRU(latent_dim,\n",
    "                        return_sequences=True,\n",
    "                        return_state=True,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        dropout=0.2,\n",
    "                        recurrent_dropout=0.2)\n",
    "        self.embedding = Embedding(vocab_size, latent_dim, mask_zero=True)\n",
    "        self.fc = Dense(vocab_size, activation='softmax')\n",
    "        self.attention = BahdanauAttention2(self.latent_dim)\n",
    "\n",
    "    def call(self, x, hidden, enc_output, encoder_mask):\n",
    "        print(f\"x: {x.shape}\")\n",
    "        print(f\"hidden: {hidden.shape}\")\n",
    "        print(f\"enc_output: {enc_output.shape}\")\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        rnn_output, rnn_state = self.lstm(x)\n",
    "        print(f\"rnn_output: {rnn_output.shape}\")\n",
    "        \n",
    "        context_vector, attention_weights = self.attention(rnn_output, enc_output, x._keras_mask, encoder_mask)\n",
    "        \n",
    "        # context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
    "        \n",
    "        x = tf.concat([context_vector, rnn_output], axis=-1)\n",
    "        \n",
    "        #NOTE: does reshape needed?\n",
    "        # output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        y = self.fc(x)\n",
    "\n",
    "        return y, rnn_state\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder = Decoder(num_decoder_tokens, latent_dim, batch_size)\n",
    "decoder_outputs, _ = decoder(decoder_inputs, hidden=state, enc_output=encoder_outputs, encoder_mask=encoder_embedding_mask)\n",
    "\n",
    "\n",
    "print(f\"decoder_inputs: {decoder_inputs.shape}\")\n",
    "print(f\"state: {state.shape}\")\n",
    "print(f\"decoder_outputs: {decoder_outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c57d6ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1 (Encoder)             ((None, None, 128),  380416      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3 (Decoder)             ((None, None, 3211), 1335435     input_6[0][0]                    \n",
      "                                                                 encoder_1[0][0]                  \n",
      "                                                                 encoder_1[0][2]                  \n",
      "                                                                 encoder_1[0][1]                  \n",
      "==================================================================================================\n",
      "Total params: 1,715,851\n",
      "Trainable params: 1,715,851\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    # NOTE: this learning rate is for at least 16,000 sample on GPU server...\n",
    "    # initial_learning_rate=0.005,\n",
    "    # decay_steps=3200,\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=200,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler, clipnorm=1.0), loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74f6cc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 10:47:18.308829: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 657612800 exceeds 10% of free system memory.\n",
      "2025-06-23 10:47:22.544979: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2025-06-23 10:47:22.651525: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2198200000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "x: (16, 32)\n",
      "x: (16, 32)\n",
      "hidden: (16, 128)\n",
      "enc_output: (16, 32, 128)\n",
      "rnn_output: (16, 32, 128)\n",
      "mask: (16, 32)\n",
      "encoder_mask: (16, 32)\n",
      "x: (16, 32)\n",
      "x: (16, 32)\n",
      "hidden: (16, 128)\n",
      "enc_output: (16, 32, 128)\n",
      "rnn_output: (16, 32, 128)\n",
      "mask: (16, 32)\n",
      "encoder_mask: (16, 32)\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7343x: (16, 32)\n",
      "x: (16, 32)\n",
      "hidden: (16, 128)\n",
      "enc_output: (16, 32, 128)\n",
      "rnn_output: (16, 32, 128)\n",
      "mask: (16, 32)\n",
      "encoder_mask: (16, 32)\n",
      "100/100 [==============================] - 29s 222ms/step - loss: 1.7327 - val_loss: 1.4438\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 1.3721 - val_loss: 1.4550\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.3165 - val_loss: 1.4659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f920eca4c10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "        batch_size=batch_size,\n",
    "        epochs=3,\n",
    "        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6221f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3811ec83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "encoder_1 (Encoder)          ((None, None, 128), (None 380416    \n",
      "=================================================================\n",
      "Total params: 380,416\n",
      "Trainable params: 380,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, [encoder_outputs, state, encoder_embedding_mask])\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44f4a9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (None, None)\n",
      "hidden: (None, 128)\n",
      "enc_output: (None, None, 128)\n",
      "rnn_output: (None, None, 128)\n",
      "mask: (None, None)\n",
      "encoder_mask: (None, None)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           [(None, None, 128)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3 (Decoder)             ((None, None, 3211), 1335435     input_6[0][0]                    \n",
      "                                                                 input_17[0][0]                   \n",
      "                                                                 input_18[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,335,435\n",
      "Trainable params: 1,335,435\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_state_input = Input(shape=(latent_dim,))\n",
    "the_encoder_output = Input(shape=(None, latent_dim,))\n",
    "the_encoder_mask = Input(shape=(None,), dtype=tf.bool)\n",
    "\n",
    "decoder_outputs, decoder_state = decoder(\n",
    "    decoder_inputs, hidden=decoder_state_input, enc_output=the_encoder_output, encoder_mask=the_encoder_mask)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_state_input] + [the_encoder_output] + [the_encoder_mask],\n",
    "    [decoder_outputs] + [decoder_state])\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53352f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (None, 32)\n",
      "target_seq: [[734.]]\n",
      "x: (None, 1)\n",
      "hidden: (None, 128)\n",
      "enc_output: (None, 32, 128)\n",
      "rnn_output: (None, 1, 128)\n",
      "mask: (None, 1)\n",
      "encoder_mask: (None, 32)\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "-\n",
      "Input sentence: ['keep', 'off', 'the', 'grass']\n",
      "Decoded sentence: 我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我\n",
      "target_seq: [[734.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "-\n",
      "Input sentence: ['mom', 'is', 'getting', 'dinner', 'ready']\n",
      "Decoded sentence: 我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我\n",
      "target_seq: [[734.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "target_seq: [[2367.]]\n",
      "-\n",
      "Input sentence: [\"let's\", 'play', 'soccer']\n",
      "Decoded sentence: 你你你你你你你你你你你你你你你你你你你你你你你你你你你你你你你你你\n",
      "target_seq: [[734.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "-\n",
      "Input sentence: ['tom', \"can't\", 'go', 'home', 'until', 'after', '2:30']\n",
      "Decoded sentence: 我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我\n",
      "target_seq: [[734.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "-\n",
      "Input sentence: ['i', 'will', 'wait', 'here', 'till', 'he', 'comes']\n",
      "Decoded sentence: 我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我\n",
      "target_seq: [[734.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "-\n",
      "Input sentence: ['put', 'the', 'chair', 'in', 'front', 'of', 'the', 'desk']\n",
      "Decoded sentence: 我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我\n",
      "target_seq: [[734.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "-\n",
      "Input sentence: ['a', 'cafeteria', 'is', 'a', 'self-service', 'style', 'restaurant']\n",
      "Decoded sentence: 我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我\n",
      "target_seq: [[734.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "-\n",
      "Input sentence: ['tom', 'encouraged', 'his', 'son', 'to', 'study', 'french']\n",
      "Decoded sentence: 我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我\n",
      "target_seq: [[734.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "-\n",
      "Input sentence: ['i', 'was', 'surprised', 'to', 'see', 'a', 'lion']\n",
      "Decoded sentence: 我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我\n",
      "target_seq: [[734.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "target_seq: [[1763.]]\n",
      "-\n",
      "Input sentence: ['where', 'is', 'the', 'nearest', 'police', 'station']\n",
      "Decoded sentence: 我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我我\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    encoder_output_value, states_value, mask_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['\\t']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        print(f\"target_seq: {target_seq}\")\n",
    "        \n",
    "        output_tokens, the_decoder_state = decoder_model.predict(\n",
    "            [target_seq] + [states_value] + [encoder_output_value] + [mask_value])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        #NOTE: maybe another way to do it???? maybe not\n",
    "        # target_seq = np.append(target_seq, [[sampled_token_index]], axis=1)\n",
    "\n",
    "        # Update states\n",
    "        states_value = the_decoder_state\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(10):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c1b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
